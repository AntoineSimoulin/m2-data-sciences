{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP 1 : Apprentissage supervis√© pour le NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://monkeylearn.com/static/636fe46cd113f28c9b796e53f34c5621/f9c26/Use-Cases-Applications%402x.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les applications de la classification de texte\n",
    "\n",
    "La classification de texte est un cas d'usage tr√®s classique du NLP qui peut √™tre d√©clin√© pour plusieurs applications. Par exemple :\n",
    "* L'analyse de sentiments\n",
    "* La d√©tection de Spam dans les Emails\n",
    "* Le suivi de tendances sur les r√©seaux sociaux\n",
    "* La d√©tection de m√©contentement pour les services clients üò°üò° \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Le Benchmark FLUE \n",
    "\n",
    "FLUE <span class=\"badge badge-secondary\">(Le et al., 2010)</span> est un bencharmk d'√©valuation des syst√®mes fran√ßais de NLP, analogue au c√©l√®bre r√©f√©rentiel GLUE pour l'anglais. L'objectif est de faciliter la reproductibilit√© des exp√©riences et le partage des mod√®les et des progr√®s sur la langue fran√ßaise. Les t√¢ches et les donn√©es sont issus de travaux existants.\n",
    "\n",
    "Le r√©f√©rentiel d‚Äô√©valuation FLUE est compos√© de 7 t√¢ches correspondant √† diff√©rents niveaux d‚Äôanalyse\n",
    "(syntaxique, s√©mantique) du traitement automatique du fran√ßais. On s'interesse aujourd'hui √† trois des t√¢ches propos√©es dans le Benchmark.\n",
    "\n",
    "<b>Classification de texte</b>\n",
    "\n",
    "Le corpus d‚Äôanalyse de sentiments translingue CLS <span class=\"badge badge-secondary\">(Prettenhofer & Stein, 2010)</span> est constitu√© de critiques issues du site Amazon pour trois cat√©gories de produits (livres, DVD et musique) en quatre langues : anglais, fran√ßais, allemand et japonais. Chaque √©chantillon contient une critique associ√©e √† une note allant de 1 √† 5. Suivant <span class=\"badge badge-secondary\">Blitzer et al. (2006)</span> et <span class=\"badge badge-secondary\">Prettenhofer & Stein (2010)</span>, les √©valuations avec 3 √©toiles sont √©cart√©es et la note est binaris√©e avec un seuil de 3. Pour chaque cat√©gorie de produit, nous construisons des ensembles d‚Äôapprentissage et de test qui sont √©quilibr√©s. Les donn√©es de test contiennent ainsi 2000 avis en fran√ßais.\n",
    "\n",
    "<b>Identification de paraphrases</b> \n",
    "\n",
    "Cette t√¢che consiste √† identifier si des paires de phrases sont s√©mantiquement √©quivalentes ou non. PAWS-X est un ensemble de donn√©es multilingues pour l‚Äôidentification des paraphrases <span class=\"badge badge-secondary\">(Yang et al., 2019a)</span>. Il s‚Äôagit de l‚Äôextension de la t√¢che PAWS <span class=\"badge badge-secondary\">(Zhang et al., 2019)</span> pour l‚Äôanglais √† six autres langues : fran√ßais, espagnol, allemand, chinois, japonais et cor√©en. <span class=\"badge badge-secondary\">Yang et al. (2019a)</span> ont utilis√© la traduction automatique pour cr√©er les corpus de ces autres langues mais les ensembles de d√©veloppement et de test pour chaque langue sont traduits manuellement. Nous prenons √† nouveau la partie fran√ßaise pour FLUE.\n",
    "\n",
    "\n",
    "<b>Natural Language Inference (NLI)</b>\n",
    "\n",
    "Cette t√¢che, √©galement connue sous le nom de reconnaissance d‚Äôimplications textuelles (RTE), consid√®re une pr√©misse (p) et une hypoth√®se (h) et consiste √† d√©terminer si p implique, contredit ou n‚Äôimplique ni ne contredit h. Le corpus Cross-lingual NLI Corpus <span class=\"badge badge-secondary\">(Conneau et al., 2018, XNLI)</span> √©tend l‚Äôensemble de d√©veloppement et de test du corpus Multi Genre Natural Language Inference corpus <span class=\"badge badge-secondary\">(Williams et al., 2018, MultiNLI)</span> √† 15 langues. Les ensembles de d√©veloppement et de test pour chaque langue consistent en 7 500 exemples annot√©s manuellement, soit un total de 112 500 paires de phrases annot√©es avec les √©tiquettes entailment, contradiction ou neutre. FLUE int√®gre la partie fran√ßaise de ce corpus.\n",
    "\n",
    "\n",
    "La table ci-dessous pr√©sente les R√©sultats finaux sur les t√¢ches de FLUE.\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td style=\"text-align:center;\"><b>T√¢che</b></td>\n",
    "    <td style=\"text-align:center;\" colspan=\"3\"><b><span style='background:yellow'> Classification</span></b></td>\n",
    "    <td style=\"text-align:center;\" rowspan=\"2\"><b>Paraphrase</b></td>\n",
    "    <td style=\"text-align:center;\" rowspan=\"2\"><b>NLI</b></td>\n",
    "    <td style=\"text-align:center;\" colspan=\"2\" rowspan=\"2\"><b>Constituants</b></td>\n",
    "    <td style=\"text-align:center;\" colspan=\"2\" rowspan=\"2\"><b>D√©pendances</b></td>\n",
    "    <td style=\"text-align:center;\" colspan=\"2\"><b>D√©sambigu√Øsation</b></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"text-align:center;\"><b>Section</b></td>\n",
    "    <td style=\"text-align:center;\"><b><span style='background:yellow'> Livres</span></b></td>\n",
    "    <td style=\"text-align:center;\"><b><span style='background:yellow'> DVD</span></b></td>\n",
    "    <td style=\"text-align:center;\"><b><span style='background:yellow'> Musique</span></b></td>\n",
    "    <td style=\"text-align:center;\"><b>Noms</b></td>\n",
    "    <td style=\"text-align:center;\"><b>Verbes</b></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"text-align:center;\">Mesure </td>\n",
    "    <td style=\"text-align:center;\">Acc.</td>\n",
    "    <td style=\"text-align:center;\">Acc.</td>\n",
    "    <td style=\"text-align:center;\">Acc.</td>\n",
    "    <td style=\"text-align:center;\">Acc.</td>\n",
    "    <td style=\"text-align:center;\">Acc.</td>\n",
    "    <td style=\"text-align:center;\">F1</td>\n",
    "    <td style=\"text-align:center;\">POS</td>\n",
    "    <td style=\"text-align:center;\">UAS</td>  \n",
    "    <td style=\"text-align:center;\">LAS</td>\n",
    "    <td style=\"text-align:center;\">F1</td>\n",
    "    <td style=\"text-align:center;\">F1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"text-align:center;\">Etate de l'art ant. </td>\n",
    "    <td style=\"text-align:center;\">91.2</td>\n",
    "    <td style=\"text-align:center;\">89.6</td>\n",
    "    <td style=\"text-align:center;\">93.4</td>\n",
    "    <td style=\"text-align:center;\">66.2</td>\n",
    "    <td style=\"text-align:center;\">80.1 / 85.2</td>\n",
    "    <td style=\"text-align:center;\">87.4</td>\n",
    "    <td style=\"text-align:center;\"></td>\n",
    "    <td style=\"text-align:center;\">89.2</td>\n",
    "    <td style=\"text-align:center;\">85.9</td>  \n",
    "    <td style=\"text-align:center;\">-</td>\n",
    "    <td style=\"text-align:center;\">43.0</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"text-align:center;\">Sans pr√©-entr.</td>\n",
    "    <td style=\"text-align:center;\">-</td>\n",
    "    <td style=\"text-align:center;\">-</td>\n",
    "    <td style=\"text-align:center;\">-</td>\n",
    "    <td style=\"text-align:center;\"></td>\n",
    "    <td style=\"text-align:center;\"></td>\n",
    "    <td style=\"text-align:center;\">83.9</td>\n",
    "    <td style=\"text-align:center;\">97.5</td>\n",
    "    <td style=\"text-align:center;\">88.9</td>\n",
    "    <td style=\"text-align:center;\">85.1</td>  \n",
    "    <td style=\"text-align:center;\">50.0</td>\n",
    "    <td style=\"text-align:center;\">-</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"text-align:center;\">FastText</td>\n",
    "    <td style=\"text-align:center;\">-</td>\n",
    "    <td style=\"text-align:center;\">-</td>\n",
    "    <td style=\"text-align:center;\">-</td>\n",
    "    <td style=\"text-align:center;\"></td>\n",
    "    <td style=\"text-align:center;\"></td>\n",
    "    <td style=\"text-align:center;\">83.6</td>\n",
    "    <td style=\"text-align:center;\">97.7</td>\n",
    "    <td style=\"text-align:center;\">86.3</td>\n",
    "    <td style=\"text-align:center;\">82.0</td>  \n",
    "    <td style=\"text-align:center;\">49.4</td>\n",
    "    <td style=\"text-align:center;\">34.9</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"text-align:center;\">mBERT</td>\n",
    "    <td style=\"text-align:center;\">86.2</td>\n",
    "    <td style=\"text-align:center;\">86.9</td>\n",
    "    <td style=\"text-align:center;\">86.7</td>\n",
    "    <td style=\"text-align:center;\">89.3</td>\n",
    "    <td style=\"text-align:center;\">76.9</td>\n",
    "    <td style=\"text-align:center;\">87.5</td>\n",
    "    <td style=\"text-align:center;\">98.1</td>\n",
    "    <td style=\"text-align:center;\">89.5</td>\n",
    "    <td style=\"text-align:center;\">85.9</td>  \n",
    "    <td style=\"text-align:center;\">56.5</td>\n",
    "    <td style=\"text-align:center;\">44.9</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"text-align:center;\">CamemBERT</td>\n",
    "    <td style=\"text-align:center;\">93.4</td>\n",
    "    <td style=\"text-align:center;\">92.7</td>\n",
    "    <td style=\"text-align:center;\">94.2</td>\n",
    "    <td style=\"text-align:center;\">89.8</td>\n",
    "    <td style=\"text-align:center;\">81.2</td>\n",
    "    <td style=\"text-align:center;\">88.4</td>\n",
    "    <td style=\"text-align:center;\">98.2</td>\n",
    "    <td style=\"text-align:center;\">91.4</td>\n",
    "    <td style=\"text-align:center;\">88.1</td>  \n",
    "    <td style=\"text-align:center;\">56.1</td>\n",
    "    <td style=\"text-align:center;\">51.1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"text-align:center;\">FlauBERT-base</td>\n",
    "    <td style=\"text-align:center;\">93.4</td>\n",
    "    <td style=\"text-align:center;\">92.5</td>\n",
    "    <td style=\"text-align:center;\">94.3</td>\n",
    "    <td style=\"text-align:center;\">89.9</td>\n",
    "    <td style=\"text-align:center;\">81.3</td>\n",
    "    <td style=\"text-align:center;\">89.1</td>\n",
    "    <td style=\"text-align:center;\">98.1</td>\n",
    "    <td style=\"text-align:center;\">91.6</td>\n",
    "    <td style=\"text-align:center;\">88.4</td>  \n",
    "    <td style=\"text-align:center;\">54.9 / 57.9</td>\n",
    "    <td style=\"text-align:center;\">47.4</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "<span class=\"badge badge-secondary\">(Le et al., 2010)</span> Hang Le, Lo√Øc Vial, Jibril Frej, Vincent Segonne, Maximin Coavoux, Benjamin Lecouteux, Alexandre Allauzen, Beno√Æt Crabb√©, Laurent Besacier, Didier Schwab: FlauBERT: Unsupervised Language Model Pre-training for French. LREC 2020: 2479-2490"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute if running in Colab\n",
    "\n",
    "# !pip install -q scikit-learn==0.23.2 matplotlib==3.3.2 pandas==1.1.3 lime==0.2.0 umap-learn==0.4.6 nltk==3.5 spacy==2.3.2 install umap-learn[plot], unidecode\n",
    "# !python3 -m spacy download fr_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if running Colab, restart after libraries installation (Red√©marrer l'environnement d'ex√©cution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # python base math library\n",
    "import pandas as pd # data structure\n",
    "\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set font\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = 'Helvetica'\n",
    "\n",
    "# set the style of the axes and the text color\n",
    "plt.rcParams['axes.edgecolor']='#333F4B'\n",
    "plt.rcParams['axes.linewidth']=0.8\n",
    "plt.rcParams['xtick.color']='#333F4B'\n",
    "plt.rcParams['ytick.color']='#333F4B'\n",
    "plt.rcParams['text.color']='#333F4B'\n",
    "\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "# IPython automatically reload all changed code\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Inline Figures with matplotlib\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!test -d m2-data-sciences || git clone https://github.com/AntoineSimoulin/m2-data-sciences.git\n",
    "sys.path.append('m2-data-sciences/src')\n",
    "from plots import plot_word_counter, plot_zipf\n",
    "from load_flue_datasets import load_cls_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!test -d titulus || git clone https://github.com/AntoineSimoulin/titulus.git\n",
    "sys.path.append('titulus')\n",
    "try:\n",
    "    from titulus import color, print_\n",
    "except:\n",
    "    from titulus.titulus import color, print_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classification de texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://monkeylearn.com/static/507a7b5d0557f416857a038f553865d1/5040b/text_process_training.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Chargement des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './m2-data-sciences/TP1 - Apprentissage supervis√© pour le NLP/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_books, y_books = load_cls_dataset(os.path.join(local_dir, 'data'), 'books')\n",
    "X_dvd, y_dvd = load_cls_dataset(os.path.join(data_dir, 'data'), 'dvd')\n",
    "X_music, y_music = load_cls_dataset(os.path.join(data_dir, 'data'), 'music')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame.from_dict(\n",
    "    {'reviews': X_books['train'] + X_dvd['train'] + X_music['train'],\n",
    "     'section': ['books' for _ in range(len(X_books['train']))] \\\n",
    "     + ['dvd' for _ in range(len(X_dvd['train']))] \\\n",
    "     + ['music' for _ in range(len(X_music['train']))]})\n",
    "\n",
    "y_train = y_books['train'] + y_dvd['train'] + y_music['train']\n",
    "\n",
    "X_valid_df = pd.DataFrame.from_dict(\n",
    "    {'reviews': X_books['valid'] + X_dvd['valid'] + X_music['valid'],\n",
    "     'section': ['books' for _ in range(len(X_books['valid']))] \\\n",
    "     + ['dvd' for _ in range(len(X_dvd['valid']))] \\\n",
    "     + ['music' for _ in range(len(X_music['valid']))]})\n",
    "\n",
    "y_valid = y_books['valid'] + y_dvd['valid'] + y_music['valid']\n",
    "\n",
    "class_names = ['N√©gatif', 'Positif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p><b>Exercice :</b> Comparer la distribution des labels positifs / n√©gatifs.</p>\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/plot_labels_distribution.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p><b>Exercice :</b> Comparer la distribution des sections <i>books</i>, <i>dvd</i> et <i>music</i>.</p>\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/plot_sections_distribution.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p><b>Exercice :</b> Comparer la distribution de la longueur des phrases sur le jeu de donn√©es d'entrainement et de validation.</p>\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/plot_sentence_length_distribution.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p><b>Exercice :</b> Etudier la distribution des caract√®res dans corpus.</p>\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/characters_distribution.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p><b>Exercice :</b> V√©rifier s'il y a des donn√©es manquantes (labels, reviews).</p>\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install unidecode\n",
    "import unidecode\n",
    "import re # Regular Expression (Regex) in Python\n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS\n",
    "from spacy.tokens import Doc\n",
    "nlp = spacy.load('fr_core_news_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p><b>Exercice :</b> Effectuer la tokenization du jeu de donn√©es. Pour cela cr√©er une nouvelle colonne <b>tokens</b> dans la DataFrame. Vous pouvez utiliser la m√©thode de votre choix, Spacy, regex ...</p>\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/tokenization.py\n",
    "# Tokenizer le texte\n",
    "\n",
    "def tokenize(text):\n",
    "    \n",
    "    #TODO Complete\n",
    "    \n",
    "    return tokens  \n",
    "\n",
    "X_train_df['tokens'] = X_train_df['reviews'].apply(tokenize)\n",
    "X_valid_df['tokens'] = X_valid_df['reviews'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardisation de texte : suppression des accents et mettre en minuscules\n",
    "\n",
    "def remove_accents(token):\n",
    "    return unidecode.unidecode(token)\n",
    "\n",
    "X_train_df['tokens'] = X_train_df['tokens'].apply(lambda x: [remove_accents(t) for t in x])\n",
    "X_valid_df['tokens'] = X_valid_df['tokens'].apply(lambda x: [remove_accents(t) for t in x])\n",
    "\n",
    "X_train_df['tokens'] = X_train_df['tokens'].apply(lambda x: [t.lower() for t in x])\n",
    "X_valid_df['tokens'] = X_valid_df['tokens'].apply(lambda x: [t.lower() for t in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization : on ram√®ne chaque mot √† son \"lem\", pour les verbes, la forme non conjugu√©e \n",
    "\n",
    "def custom_tokenizer(text):\n",
    "    tokens = tokenize(text)\n",
    "    return Doc(nlp.vocab, tokens)\n",
    "\n",
    "nlp.tokenizer = custom_tokenizer\n",
    "\n",
    "doc = nlp(X_train_df.loc[0, 'reviews'])\n",
    "for token in doc:\n",
    "    print(token, token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    doc = nlp(X_train_df.loc[0, 'reviews'])\n",
    "    return [token.lemma_ for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatize(X_train_df.loc[0, 'reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming : on enl√®ve les \"terminaisons\" des mots\n",
    "\n",
    "\n",
    "stemmer = FrenchStemmer()\n",
    "\n",
    "for token in X_train_df.loc[0, 'tokens']:\n",
    "    print(token, stemmer.stem(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmatize(tokens):\n",
    "    return [stemmer.stem(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmatize(X_train_df.loc[0, 'tokens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p><b>Exercice :</b> Observer l'impact de la stemmatisation sur le jeu de donn√©es.</p>\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/stemming_impact.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer  \n",
    "# Sklearn is a famous french ML library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x-RwI4kdjnrw"
   },
   "source": [
    "On va chercher √† encoder les donn√©es comme discut√© pendant le premier cours. Le texte va √™tre \"vectoris√©\" afin de pouvoir √™tre trait√© par des algorithmes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w2MX8tqsjnrw"
   },
   "source": [
    "**Bag of Words** C'est la repr√©sentation la plus simple. On attribue index √† chacun des mots apparaissant dans le corpus d'entrainement. On peut ensuite repr√©senter chaque document par un vecteur X indiquant la pr√©sence ou l'absence de chaque mot 'w' dans le dictionnaire. La taille du vocabulaire est g√©n√©ralement comprise entre 50.000 et 100.000 mots.\n",
    "\n",
    "De plus la majorit√© des valeurs de X sont nulles puisque pour un document donn√©, seul quelques centaines de mots sont utilis√©s. Ainsi, le bag of words est une repr√©sentation <i>sparse</i> de <i>grande dimension</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On consid√®re ce corpus exemple.\n",
    "\n",
    "docs = np.array([\n",
    "        \"Je n'aime pas les livres !\",\n",
    "        'Un livre tr√®s complet !',\n",
    "        'Clairement un livre pour les filles !'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p><b>Exercice :</b> Etablir le vocabulaire associ√© au corpus et la repr√©sentation BoW de la premi√®re phrase.</p>\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7CEIcprxjnrx"
   },
   "source": [
    "**Prise en compte de l'aspect fr√©quentiel** chaque text est repr√©sent√© par un vecteur indiquant la fr√©quence de chaque token dans le text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p><b>Exercice :</b> Etablir la repr√©sentation fr√©quentielle de la premi√®re phrase.</p>\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "seiU6grVjnry"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fEVt0EJ0jnr0",
    "outputId": "749d8303-107c-43b2-bdcf-44269a9a640d"
   },
   "outputs": [],
   "source": [
    "# On peut aussi utiliser la librairie sklearn\n",
    "\n",
    "cv = CountVectorizer()\n",
    "tf = cv.fit_transform(docs).toarray()\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WIu-hq-Ijnr3",
    "outputId": "a080979a-493e-42ec-e4af-5dba043b7640"
   },
   "outputs": [],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M1osTllhjnr4",
    "outputId": "23acdc3c-cac9-4317-a041-5aa778c2e48a"
   },
   "outputs": [],
   "source": [
    "list(zip(cv.get_feature_names(), cv.transform([docs[2]]).toarray()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uc3DOEnnjnr7"
   },
   "source": [
    "**TF-IDF (Term Frequency - Inverse Document Frequency)**: On l'a vu en cours, le probl√®me de ce type d'approche c'est que les mots ont une fr√©quence d'apparition sp√©cifique dans le texte. Pour corriger ce ph√©nom√®ne, on s'appuie sur la repr√©sentation Tf-Idf\n",
    "\n",
    "Cette m√©thode cherche √† r√©duire les poids des mots qui apparaissent dans de nombreux documents du corpus et qui portent donc moins d'information que les mots plus rares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u2w0Y84rjnr8"
   },
   "source": [
    "**Calcul des pond√©rations Tf-Idf** \n",
    "\n",
    "$$\\text{tf-idf}(t, d) = \\text{tf}(t, d) \\times \\text{idf}(t)$$\n",
    "\n",
    "ou `idf` et la **inverse document frequency** et `tf` et la **fr√©quence du mot** dans le document calcul√©e pr√©c√©dement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calcul du terme TF** : TF peut √™tre calcul√©e de plusieurs mani√®res correspond √† la fr√©quence d'occurence du mot dans le document.\n",
    "\n",
    "**Calcul du terme DF** : On d√©finit la *document frequency* d'un mot dans le corpus, comme le nombre de documents o√π ce mot apparait : $\\mathrm{df}(t) = |\\{d \\in D: t \\in d\\}|$\n",
    "\n",
    "**Calcul de la IDF** : IDF mesure l'importance d'un mot vis √† vis de l'ensemble du corpus ($N$ est le nombre de documents dans le corpus). Elle est calcul√©e en utilisant la notion de *document frequency* $\\text{df}(d,t)$, qui d√©signe simplement le nombre de documents $d$ qui contiennent le term $t$. On peut ainsi d√©finir l'idf commme suit :\n",
    "\n",
    "$$\\text{idf}(t) = log{\\frac{n_d}{1+\\text{df}(d,t)}},$$ \n",
    "avec    $n_d$: Nombre total de documents\n",
    "\n",
    "**Remarque 1 :** la constante 1 est ajout√©e au d√©nominateur pour √©viter les cas de division par 0. :\n",
    "\n",
    "**Remarque 2 :** `Sklearn` utilise une d√©finition diff√©rente de l'IDF classique: \n",
    "$$  \\mathrm{idf}(t) = 1 + \\log \\left( \\frac{N}{\\mathrm{df}(t)}\\right) $$\n",
    "\n",
    "Et dans le cas ou `smooth_idf = True` $$\\mathrm{idf}(t) = 1+ \\log \\left( \\frac{1+N}{1+\\mathrm{df}(t)}\\right)   $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C5T3WeKTjnr9"
   },
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p><b>Exercice :</b> Calculer la repr√©sentation du premier document 'Je n'aime pas les livres !' √©tant donn√© les pond√©rations idf du corpus exemple.</p>\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z3IVOWo8jnr9",
    "outputId": "c22aeaca-93a8-4e09-f976-7bf6e931c2b4"
   },
   "outputs": [],
   "source": [
    "# %load solutions/compute_idf.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t-xKBi5Mjnr_",
    "outputId": "40d48dc0-5dac-4552-fa4e-a7357eb5c340"
   },
   "outputs": [],
   "source": [
    "list(zip(tfidf_vec.get_feature_names(), tfidf_vec.transform([docs[2]]).toarray()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oa8DMvK8jnr-",
    "outputId": "79984d5b-7310-451e-8dab-cb8c73a65d65"
   },
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(vocabulary=cv.vocabulary_)\n",
    "tfidf_vec.fit(docs)\n",
    "tfidf_vec.transform(docs).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p><b>Exercice :</b> Retrouver la repr√©sentation obtenue avec le <b>countvectorizer</b> en utilisant le Tf-Idf de Sklearn.</p>\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "12k4SwXyjnsB",
    "outputId": "81c6024c-a64b-4c43-8fa7-46d1b6854f49"
   },
   "outputs": [],
   "source": [
    "# %load solutions/count_with_tfidf.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ztkoNvlsjnsC"
   },
   "source": [
    "<b>Les param√®tres du Tf-Idf : S√©lection de features</b>\n",
    "\n",
    "L'ensemble des documents du corpus peuvent contenir un tr√®s grand nombre de tokens distincts ainsi que de ngrams et de caract√®res. Ainsi la repr√©sentation obtenur peut √™tre de tr√®s grande dimension. Pourtant l'ensemble des tokens (features) ne contribuent pas tous √† augmenter la pr√©cision des algorithmes de classifications. \n",
    "\n",
    "Nous pouvons donc ne pas tenir compte de certains tokens. Pour cela il est possible de jouer sur de nombreux param√®tres du Tf-Idf. On consid√®re g√©n√©ralement que 20,000 features sont amplement suffisants. De plus un tr√®s grand nombre de features peut conduire √† un ph√©nom√®ne d'overfitting et √† une d√©gradation des performances de l'algorithme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dnJdapeWjnsC"
   },
   "source": [
    "> **Param√®tre `analyzer`** Prend en argument ‚Äòword‚Äô pour effectuer la transformation sur les mots, ou ‚Äòchar‚Äô pour effectuer la transformation sur les lettres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M960F08HjnsC",
    "outputId": "5fc309bb-507a-4f6e-e31c-1559c67c7a80"
   },
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(analyzer=\"word\")\n",
    "X = vec.fit_transform(X_train_df['reviews'])\n",
    "print(\"Taille du vocabulaire: \"+str(len(vec.vocabulary_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N9eAYct9jnsD",
    "outputId": "90b84df5-5f1d-4ad1-953b-f747950cb3cb"
   },
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(analyzer=\"char\")\n",
    "X = vec.fit_transform(X_train_df['reviews'])\n",
    "print(\"Taille du vocabulaire: \"+str(len(vec.vocabulary_)))\n",
    "print(vec.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qH4P_0L7jnsE"
   },
   "source": [
    "> **Param√®tres `max_df` et `min_df`** Prend en argument un float compris dans [0.0, 1.0] ou un int. max_df permet de supprimer les termes de fr√©quence √©lev√©e et min_df permet de supprimer les termes de fr√©quence faible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VaeLpHCkjnsE",
    "outputId": "04ec50f8-6b45-4238-bc7a-8894e129c7db"
   },
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(max_df=0.8) # min_df=5\n",
    "X = vec.fit_transform(X_train_df['reviews'])\n",
    "print(\"Taille du vocabulaire: \"+str(len(vec.vocabulary_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Z6Gd9AzjnsG",
    "outputId": "cd34c8c9-6c6d-4f9e-f79c-33e5d448baf5"
   },
   "outputs": [],
   "source": [
    "docs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oQTL3U-RjnsH",
    "outputId": "be3256bd-5c75-4e6a-972c-5b887ed37265"
   },
   "outputs": [],
   "source": [
    "[x for x in list(zip(vec.get_feature_names(), \n",
    "                     vec.transform([docs[2]]).toarray()[0])) \n",
    "            if x[0] in cv.get_feature_names()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IP-cfM6CjnsI"
   },
   "source": [
    "> **Param√®tre `max_features`** Permet de limiter le nombre de mots utilis√©s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8YqrWI8ljnsJ",
    "outputId": "edc915f1-0a51-488e-b1e8-bc0c284d0f27"
   },
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(max_features=10000)\n",
    "X = vec.fit_transform(X_train_df['reviews'])\n",
    "print(\"Taille du vocabulaire: \"+str(len(vec.vocabulary_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cVJsUmjojnsK",
    "outputId": "e2150d91-07dd-4308-a8d3-30feb4d02828"
   },
   "outputs": [],
   "source": [
    "[x for x in list(zip(vec.get_feature_names(), \n",
    "                     vec.transform([docs[2]]).toarray()[0])) \n",
    "            if x[0] in cv.get_feature_names()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uXgiqipVjnsM"
   },
   "source": [
    "> **Param√®tre `stop_words`** Permet de supprimer certains mots sp√©cifiques du vocabulaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AHA15TI1jnsM",
    "outputId": "80984ff1-f09c-4462-c7bc-7bd5674c901c"
   },
   "outputs": [],
   "source": [
    "print(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GlQv-eJtjnsN",
    "outputId": "0f1eed25-4054-44c6-a7f4-c0940e674767"
   },
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(stop_words=fr_stop)\n",
    "X = vec.fit_transform(X_train_df['reviews'])\n",
    "print(\"Taille du vocabulaire: \"+str(len(vec.vocabulary_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6FVwqAodjnsP"
   },
   "source": [
    "> **Param√®tre `ngram_range`** Permet d'int√©grer dans l'espace des features des suites de mots ou de caract√®res."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AU2WFpWgjnsP",
    "outputId": "e0b9cb58-1531-4ba8-bede-2a820e1521a6"
   },
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(ngram_range = (1,2))\n",
    "X = vec.fit_transform(X_train_df['reviews'])\n",
    "print(\"Taille du vocabulaire: \"+str(len(vec.vocabulary_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kT0iaY3sjnsQ",
    "outputId": "846bdd5b-3fed-4d4a-a2aa-b7af1f7236a1"
   },
   "outputs": [],
   "source": [
    "[x for x in list(zip(vec.get_feature_names(), \n",
    "                     vec.transform([docs[2]]).toarray()[0])) \n",
    "            if x[0] in cv.get_feature_names()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BSUdAZJ8jnsR"
   },
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p><b>Exercice :</b> Supprimer les mots \"je\", \"le\" du dictionnaire de vocabulaire mais pas \"livres\" ou \"oeuvre\".</p>\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "omFx7_tojnsR",
    "outputId": "0836dcc2-f75e-4003-c446-2d74d3d4b9e3"
   },
   "outputs": [],
   "source": [
    "# %load solutions/filter_tfidf_voc.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000,\n",
    "                             max_df=0.8,\n",
    "                             min_df=5,\n",
    "                              # ngram_range=(1, 3),\n",
    "                             tokenizer=lambda x: x,\n",
    "                             lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = vectorizer.fit_transform(X_train_df['tokens'])\n",
    "X_valid_tfidf = vectorizer.transform(X_valid_df['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf_arr = X_train_tfidf.toarray()\n",
    "voc_tfidf = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=5000,\n",
    "                             ngram_range=(1, 3),\n",
    "                             tokenizer=lambda x: x,\n",
    "                             lowercase=False)\n",
    "\n",
    "X_train_counter = vectorizer.fit_transform(X_train_df['tokens'])\n",
    "X_valid_counter = vectorizer.transform(X_valid_df['tokens'])\n",
    "\n",
    "X_counter_arr = X_train_counter.toarray()\n",
    "voc_counter = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des poids en fonction de la fr√©quence\n",
    "\n",
    "idx = np.random.randint(len(X_counter_arr))\n",
    "\n",
    "tokens = X_train_df.loc[idx, 'tokens']\n",
    "token_idx = [voc_counter.index(t) if t in voc_counter else -1 for t in tokens]\n",
    "\n",
    "counter_weights = [X_counter_arr[idx, t] if t >=0 else 0 for t in token_idx]\n",
    "\n",
    "print_(' '.join(color(tokens, counter_weights, finish_hex=\"#970137\", n=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des poids TF-IDF\n",
    "\n",
    "tokens = X_train_df.loc[idx, 'tokens']\n",
    "token_idx = [voc_tfidf.index(t) if t in voc_tfidf else -1 for t in tokens]\n",
    "\n",
    "tfidf_weights = [X_tfidf_arr[idx, t] if t >=0 else 0 for t in token_idx]\n",
    "\n",
    "print_(' '.join(color(tokens, tfidf_weights, finish_hex=\"#970137\", n=10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://monkeylearn.com/static/afa7e0536886ee7152dfa4c628fe59f0/5040b/text_process_prediction.png\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate classifier\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    random_state=0, \n",
    "    solver='lbfgs',\n",
    "    multi_class='ovr',\n",
    "    penalty='l2',\n",
    "    C=1.0,\n",
    "    n_jobs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train classifier\n",
    "\n",
    "clf.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Choix de la m√©trique de performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour √©valuer les performances d'un classificateur 3 indicateurs son g√©n√©ralement √©tudi√©s :\n",
    "\n",
    "* Le **score de pr√©cision** : le taux de pr√©dictions corrects parmis les individus pr√©dits comme positifs.\n",
    "* Le **score de rappel** : le taux d'individus positifs correctement pr√©dits.\n",
    "* Le **score F1** : moyenne harmonique des scors de pr√©cision et de rappel.\n",
    "* La **matrice de confusion** permet de repr√©senter le mani√®re simple le nombre de vrais positifs, faux positifs, vrais n√©gatifs et faux n√©gatifs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric de performance train et test\n",
    "\n",
    "# Compare train and validation score to check overfitting\n",
    "# Use the validation set to do the hyper-parameter tuning\n",
    "f1_train = f1_score(y_train, clf.predict(X_train_tfidf), average='macro')\n",
    "f1_validation = f1_score(y_valid, clf.predict(X_valid_tfidf), average='macro')\n",
    "\n",
    "print(f\"Score on the train set : {'%.2f' %f1_train}\")\n",
    "print(f\"Score on the validation set : {'%.2f' %f1_validation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confusion_matrix(y_valid, clf.predict(X_valid_tfidf)), \n",
    "                      classes=class_names, \n",
    "                      title='Confusion matrix, without normalization')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_logreg_pred = clf.predict(X_valid_tfidf)\n",
    "\n",
    "print(\"Matrice de confusion de la r√©gression logistique : \")\n",
    "print(confusion_matrix(y_valid, y_logreg_pred))\n",
    "print(\"Score de pr√©cision de la r√©gression logisitique : \"+str(round(precision_score(y_valid, y_logreg_pred)*100,2)))\n",
    "print(\"Score de rappel de la r√©gression logisitique : \"+str(round(recall_score(y_valid, y_logreg_pred)*100,2)))\n",
    "print(\"Score F1 de la r√©gression logisitique : \"+str(round(f1_score(y_valid, y_logreg_pred)*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Comparaison des mod√®les : Naive Bayes, SVM, r√©gression logistique, algorithme de boosting</b>\n",
    "\n",
    "\n",
    "Maintenant que les √©tapes classiques de r√©solution d'un probl√®me de classification ont √©t√© abord√©s nous sommes arm√©s pour comparer diff√©rents mod√®les de transformation des variables et de classification √† l'aune de leurs performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p><b>Exercice :</b> Comparer le mod√®le de regression logistique avec un mod√®le de for√™t al√©atoire</p>\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/reg_vs_forest.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p><b>Exercice :</b> Evaluer l'impact de la taille du vocabulaire du tf-idf sur la pr√©cision du mod√®le</p>\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p><b>Exercice :</b> Optimiser les param√®tres du mod√®le pour obtenir une pr√©cision sup√©rieure √† 88% sur le jeu de dev. On pourra comparer faire varier plusieurs caract√©ristiques comme l'impact du pre-processing, le Stemming, Lemmatization ou encore Choix du vectorizer, count vs Tf-Idf ou le mod√®le</p>\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Choix des hyper-param√®tres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation du pipeline Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCleaner(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, do_lower=False, remove_accents=True):\n",
    "        self.do_lower = do_lower\n",
    "        self.remove_accents = remove_accents\n",
    "    \n",
    "    def _normalize(self, text):\n",
    "        return unidecode.unidecode(text)\n",
    "    \n",
    "    def fit(self, X, y=None): \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.copy()\n",
    "            if self.remove_accents:\n",
    "                X['reviews'] = X['reviews'].apply(self._normalize)        \n",
    "        else:\n",
    "            if not isinstance(X, list):\n",
    "                X = [X] \n",
    "            if self.remove_accents:\n",
    "                X = [self._normalize(x) for x in X]\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p><b>Exercice :</b> Cr√©er la class Sklearn pour la Tokenization.</p>\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/class_tokenizer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        #TODO Complete\n",
    "\n",
    "    def fit(self, X, y=None): \n",
    "        #TODO Complete\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        #TODO Complete\n",
    "       \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate classes and create Pipeline\n",
    "\n",
    "cleaner = TextCleaner()\n",
    "tokenizer = Tokenizer()\n",
    "feature_engineering = TfidfVectorizer(max_features=5000,\n",
    "                             max_df=0.8,\n",
    "                             min_df=5,\n",
    "                              # ngram_range=(1, 3),\n",
    "                             tokenizer=lambda x: x,\n",
    "                             lowercase=False)\n",
    "clf = LogisticRegression(\n",
    "    random_state=0, \n",
    "    solver='lbfgs',\n",
    "    multi_class='ovr',\n",
    "    penalty='l2',\n",
    "    C=1.0,\n",
    "    n_jobs=2\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([('cleaning', cleaner), \n",
    "                     ('tokenization', tokenizer), \n",
    "                     ('vect', feature_engineering),\n",
    "                     ('clf', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit\n",
    "pipeline.fit(X_train_df, y_train)\n",
    "pipeline.score(X_valid_df, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Mise en place de la Proc√©dure de Cross Validation\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "param_grid = {\"vect__max_df\" : [0.95,1.0],\n",
    "              \"vect__min_df\" : [1,5],\n",
    "              \"vect__max_features\" : [1000, 2000],\n",
    "              \"vect__ngram_range\" : [(1,1)],\n",
    "              \"clf__penalty\" : ['l2'],\n",
    "              \"clf__C\" : [0.1, 1.0, 10]\n",
    "              }\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, scoring='accuracy', cv=kfold, verbose=1)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(param_grid)\n",
    "t0 = time()\n",
    "grid_search.fit(X_train_df, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 Analyse des r√©sultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lime <span class=\"badge badge-secondary\">(T√∫lio Ribeiro et al., 2016)</span> est une m√©thode d'analyse des mod√®les qui cherche √† expliciter sur quelles caract√©ristiques de l'√©chantillon en entr√©e, l'algorithme s'est appuy√© pour formuler sa pr√©diction.\n",
    "\n",
    "Pour cela LIME propose de g√©n√©rer plusieurs √©chantillons proches de l'exemple d'entr√©e et d'apprendre un mod√®le lin√©aire qui cherche √† approcher les pr√©dictions du mod√®les que l'on cherche √† √©tudier sur ce jeu de donn√©es. Par exemple pour la phrase :\n",
    "\n",
    "> Un livre √©mouvant mais aussi tr√®s dr√¥le, magnifiquement √©crit, √† mettre entre toutes les mains sans h√©sitation. Si vous avez un enfant qui aime lire il pourrait l'apr√©cier √† partir de 8 ans, je pense. Et si vous avez gard√© l'envie de vous √©merveiller il vous plairat jusqu'√† 99 ans.\n",
    "\n",
    "\n",
    "On va g√©n√©rer 5000 phrases en perturbant l'exemple original, comme par exemple :\n",
    "\n",
    "> Un livre    tr√®s ,  ,        .           '     , je .      '      plairat ' 99 .\n",
    "\n",
    "> Un livre √©mouvant  aussi tr√®s ,  , √† mettre entre toutes les mains sans h√©sitation.  vous avez un enfant qui aime  il pourrait l'apr√©cier √†  de 8 ans,  . Et si vous avez gard√© l'envie de vous  il vous  jusqu'√† 99 ans.\n",
    "\n",
    "On identifie ensuite les points du jeu de donn√©es pour lesquels on n'arrive pas √† reproduire les pr√©dictions du mod√®les. Ces derniers sont identifi√©s comme des points \"saillants\".\n",
    "\n",
    "Quelques ressources :\n",
    "* Un bon post de [blog](https://www.oreilly.com/content/introduction-to-local-interpretable-model-agnostic-explanations-lime/) pour expliquer LIME.\n",
    "* Le [github](https://github.com/marcotcr/lime) du projet\n",
    "\n",
    "<span class=\"badge badge-secondary\">(T√∫lio Ribeiro et al., 2016)</span>Marco T√∫lio Ribeiro, Sameer Singh, Carlos Guestrin: \"Why Should I Trust You?\": Explaining the Predictions of Any Classifier. KDD 2016: 1135-1144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisation module intelligibilit√©\n",
    "\n",
    "# Instanciate classes and create Pipeline\n",
    "cleaner = TextCleaner()\n",
    "tokenizer = Tokenizer()\n",
    "feature_engineering = TfidfVectorizer(max_features=5000,\n",
    "                             max_df=0.8,\n",
    "                             min_df=5,\n",
    "                              # ngram_range=(1, 3),\n",
    "                             tokenizer=lambda x: x,\n",
    "                             lowercase=False)\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "pipeline = Pipeline([('cleaning', cleaner), \n",
    "                     ('tokenization', tokenizer), \n",
    "                     ('vect', feature_engineering),\n",
    "                     ('clf', clf)])\n",
    "\n",
    "pipeline.fit(X_train_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipeline.predict_proba(X_valid_df.loc[83, 'reviews']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['negatif', 'positif']\n",
    "\n",
    "explainer = LimeTextExplainer(class_names=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cf expl 139"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(X_valid_df.shape[0])\n",
    "print(idx, X_valid_df.loc[idx, 'reviews'])\n",
    "exp = explainer.explain_instance(X_valid_df.loc[idx, 'reviews'], pipeline.predict_proba, num_features=6)\n",
    "print('Document id: %d' % idx)\n",
    "print('Probability(positif) =', pipeline.predict_proba([X_valid_df.loc[idx, 'reviews']])[0,1])\n",
    "print('True class: %s' % class_names[y_valid[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9 Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install umap-learn[plot]\n",
    "import umap\n",
    "import umap.plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UMAP est un algorithme de r√©duction des dimensions. De mani√®re intutive, l'algorithme projete les repr√©sentations dans un espace de plus faible dimension en s'efforcant de respecter les distances entre les points entre l'espace de d√©part et d'arriv√©e. L'objectif est assez similaire √† l'algorithme t-SNE. Il permet de visualiser facilement les donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Projection des repr√©sentations avec UMAP\n",
    "# https://umap-learn.readthedocs.io/en/latest/document_embedding.html\n",
    "\n",
    "embedding = umap.UMAP(n_components=2, metric='hellinger').fit(X_train_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.embedding_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = umap.plot.points(embedding, labels=np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
