{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**Copyright 2021 Antoine SIMOULIN.**\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TP 1 : Apprentissage supervis√© pour le NLP"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"https://monkeylearn.com/static/636fe46cd113f28c9b796e53f34c5621/f9c26/Use-Cases-Applications%402x.png\" width=\"1000\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Les applications de la classification de texte\n",
    "\n",
    "La classification de texte est un cas d'usage tr√®s classique du NLP qui peut √™tre d√©clin√© pour plusieurs applications. Par exemple :\n",
    "* L'analyse de sentiments\n",
    "* La d√©tection de Spam dans les Emails\n",
    "* Le suivi de tendances sur les r√©seaux sociaux\n",
    "* La d√©tection de m√©contentement pour les services clients üò°üò° \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Le Benchmark FLUE \n",
    "\n",
    "FLUE <span class=\"badge badge-secondary\">(Le et al., 2010)</span> est un bencharmk d'√©valuation des syst√®mes fran√ßais de NLP, analogue au c√©l√®bre r√©f√©rentiel GLUE pour l'anglais. L'objectif est de faciliter la reproductibilit√© des exp√©riences et le partage des mod√®les et des progr√®s sur la langue fran√ßaise. Les t√¢ches et les donn√©es sont issus de travaux existants.\n",
    "\n",
    "Le r√©f√©rentiel d‚Äô√©valuation FLUE est compos√© de 7 t√¢ches correspondant √† diff√©rents niveaux d‚Äôanalyse\n",
    "(syntaxique, s√©mantique) du traitement automatique du fran√ßais. On s'interesse aujourd'hui √† trois des t√¢ches propos√©es dans le Benchmark.\n",
    "\n",
    "<b>Classification de texte</b>\n",
    "\n",
    "Le corpus d‚Äôanalyse de sentiments translingue CLS <span class=\"badge badge-secondary\">(Prettenhofer & Stein, 2010)</span> est constitu√© de critiques issues du site Amazon pour trois cat√©gories de produits (livres, DVD et musique) en quatre langues : anglais, fran√ßais, allemand et japonais. Chaque √©chantillon contient une critique associ√©e √† une note allant de 1 √† 5. Suivant <span class=\"badge badge-secondary\">Blitzer et al. (2006)</span> et <span class=\"badge badge-secondary\">Prettenhofer & Stein (2010)</span>, les √©valuations avec 3 √©toiles sont √©cart√©es et la note est binaris√©e avec un seuil de 3. Pour chaque cat√©gorie de produit, nous construisons des ensembles d‚Äôapprentissage et de test qui sont √©quilibr√©s. Les donn√©es de test contiennent ainsi 2000 avis en fran√ßais.\n",
    "\n",
    "<b>Identification de paraphrases</b> \n",
    "\n",
    "Cette t√¢che consiste √† identifier si des paires de phrases sont s√©mantiquement √©quivalentes ou non. PAWS-X est un ensemble de donn√©es multilingues pour l‚Äôidentification des paraphrases <span class=\"badge badge-secondary\">(Yang et al., 2019a)</span>. Il s‚Äôagit de l‚Äôextension de la t√¢che PAWS <span class=\"badge badge-secondary\">(Zhang et al., 2019)</span> pour l‚Äôanglais √† six autres langues : fran√ßais, espagnol, allemand, chinois, japonais et cor√©en. <span class=\"badge badge-secondary\">Yang et al. (2019a)</span> ont utilis√© la traduction automatique pour cr√©er les corpus de ces autres langues mais les ensembles de d√©veloppement et de test pour chaque langue sont traduits manuellement. Nous prenons √† nouveau la partie fran√ßaise pour FLUE.\n",
    "\n",
    "\n",
    "<b>Natural Language Inference (NLI)</b>\n",
    "\n",
    "Cette t√¢che, √©galement connue sous le nom de reconnaissance d‚Äôimplications textuelles (RTE), consid√®re une pr√©misse (p) et une hypoth√®se (h) et consiste √† d√©terminer si p implique, contredit ou n‚Äôimplique ni ne contredit h. Le corpus Cross-lingual NLI Corpus <span class=\"badge badge-secondary\">(Conneau et al., 2018, XNLI)</span> √©tend l‚Äôensemble de d√©veloppement et de test du corpus Multi Genre Natural Language Inference corpus <span class=\"badge badge-secondary\">(Williams et al., 2018, MultiNLI)</span> √† 15 langues. Les ensembles de d√©veloppement et de test pour chaque langue consistent en 7 500 exemples annot√©s manuellement, soit un total de 112 500 paires de phrases annot√©es avec les √©tiquettes entailment, contradiction ou neutre. FLUE int√®gre la partie fran√ßaise de ce corpus.\n",
    "\n",
    "\n",
    "La table ci-dessous pr√©sente les R√©sultats finaux sur les t√¢ches de FLUE.\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td style=\"text-align:center;\"><b>T√¢che</b></td>\n",
    "    <td style=\"text-align:center;\" colspan=\"3\"><b><span style='background:yellow'> Classification</span></b></td>\n",
    "    <td style=\"text-align:center;\" rowspan=\"2\"><b>Paraphrase</b></td>\n",
    "    <td style=\"text-align:center;\" rowspan=\"2\"><b>NLI</b></td>\n",
    "    <td style=\"text-align:center;\" colspan=\"2\" rowspan=\"2\"><b>Constituants</b></td>\n",
    "    <td style=\"text-align:center;\" colspan=\"2\" rowspan=\"2\"><b>D√©pendances</b></td>\n",
    "    <td style=\"text-align:center;\" colspan=\"2\"><b>D√©sambigu√Øsation</b></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"text-align:center;\"><b>Section</b></td>\n",
    "    <td style=\"text-align:center;\"><b><span style='background:yellow'> Livres</span></b></td>\n",
    "    <td style=\"text-align:center;\"><b><span style='background:yellow'> DVD</span></b></td>\n",
    "    <td style=\"text-align:center;\"><b><span style='background:yellow'> Musique</span></b></td>\n",
    "    <td style=\"text-align:center;\"><b>Noms</b></td>\n",
    "    <td style=\"text-align:center;\"><b>Verbes</b></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"text-align:center;\">Mesure </td>\n",
    "    <td style=\"text-align:center;\">Acc.</td>\n",
    "    <td style=\"text-align:center;\">Acc.</td>\n",
    "    <td style=\"text-align:center;\">Acc.</td>\n",
    "    <td style=\"text-align:center;\">Acc.</td>\n",
    "    <td style=\"text-align:center;\">Acc.</td>\n",
    "    <td style=\"text-align:center;\">F1</td>\n",
    "    <td style=\"text-align:center;\">POS</td>\n",
    "    <td style=\"text-align:center;\">UAS</td>  \n",
    "    <td style=\"text-align:center;\">LAS</td>\n",
    "    <td style=\"text-align:center;\">F1</td>\n",
    "    <td style=\"text-align:center;\">F1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"text-align:center;\">Etate de l'art ant. </td>\n",
    "    <td style=\"text-align:center;\">91.2</td>\n",
    "    <td style=\"text-align:center;\">89.6</td>\n",
    "    <td style=\"text-align:center;\">93.4</td>\n",
    "    <td style=\"text-align:center;\">66.2</td>\n",
    "    <td style=\"text-align:center;\">80.1 / 85.2</td>\n",
    "    <td style=\"text-align:center;\">87.4</td>\n",
    "    <td style=\"text-align:center;\"></td>\n",
    "    <td style=\"text-align:center;\">89.2</td>\n",
    "    <td style=\"text-align:center;\">85.9</td>  \n",
    "    <td style=\"text-align:center;\">-</td>\n",
    "    <td style=\"text-align:center;\">43.0</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"text-align:center;\">Sans pr√©-entr.</td>\n",
    "    <td style=\"text-align:center;\">-</td>\n",
    "    <td style=\"text-align:center;\">-</td>\n",
    "    <td style=\"text-align:center;\">-</td>\n",
    "    <td style=\"text-align:center;\"></td>\n",
    "    <td style=\"text-align:center;\"></td>\n",
    "    <td style=\"text-align:center;\">83.9</td>\n",
    "    <td style=\"text-align:center;\">97.5</td>\n",
    "    <td style=\"text-align:center;\">88.9</td>\n",
    "    <td style=\"text-align:center;\">85.1</td>  \n",
    "    <td style=\"text-align:center;\">50.0</td>\n",
    "    <td style=\"text-align:center;\">-</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"text-align:center;\">FastText</td>\n",
    "    <td style=\"text-align:center;\">-</td>\n",
    "    <td style=\"text-align:center;\">-</td>\n",
    "    <td style=\"text-align:center;\">-</td>\n",
    "    <td style=\"text-align:center;\"></td>\n",
    "    <td style=\"text-align:center;\"></td>\n",
    "    <td style=\"text-align:center;\">83.6</td>\n",
    "    <td style=\"text-align:center;\">97.7</td>\n",
    "    <td style=\"text-align:center;\">86.3</td>\n",
    "    <td style=\"text-align:center;\">82.0</td>  \n",
    "    <td style=\"text-align:center;\">49.4</td>\n",
    "    <td style=\"text-align:center;\">34.9</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"text-align:center;\">mBERT</td>\n",
    "    <td style=\"text-align:center;\">86.2</td>\n",
    "    <td style=\"text-align:center;\">86.9</td>\n",
    "    <td style=\"text-align:center;\">86.7</td>\n",
    "    <td style=\"text-align:center;\">89.3</td>\n",
    "    <td style=\"text-align:center;\">76.9</td>\n",
    "    <td style=\"text-align:center;\">87.5</td>\n",
    "    <td style=\"text-align:center;\">98.1</td>\n",
    "    <td style=\"text-align:center;\">89.5</td>\n",
    "    <td style=\"text-align:center;\">85.9</td>  \n",
    "    <td style=\"text-align:center;\">56.5</td>\n",
    "    <td style=\"text-align:center;\">44.9</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"text-align:center;\">CamemBERT</td>\n",
    "    <td style=\"text-align:center;\">93.4</td>\n",
    "    <td style=\"text-align:center;\">92.7</td>\n",
    "    <td style=\"text-align:center;\">94.2</td>\n",
    "    <td style=\"text-align:center;\">89.8</td>\n",
    "    <td style=\"text-align:center;\">81.2</td>\n",
    "    <td style=\"text-align:center;\">88.4</td>\n",
    "    <td style=\"text-align:center;\">98.2</td>\n",
    "    <td style=\"text-align:center;\">91.4</td>\n",
    "    <td style=\"text-align:center;\">88.1</td>  \n",
    "    <td style=\"text-align:center;\">56.1</td>\n",
    "    <td style=\"text-align:center;\">51.1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"text-align:center;\">FlauBERT-base</td>\n",
    "    <td style=\"text-align:center;\">93.4</td>\n",
    "    <td style=\"text-align:center;\">92.5</td>\n",
    "    <td style=\"text-align:center;\">94.3</td>\n",
    "    <td style=\"text-align:center;\">89.9</td>\n",
    "    <td style=\"text-align:center;\">81.3</td>\n",
    "    <td style=\"text-align:center;\">89.1</td>\n",
    "    <td style=\"text-align:center;\">98.1</td>\n",
    "    <td style=\"text-align:center;\">91.6</td>\n",
    "    <td style=\"text-align:center;\">88.4</td>  \n",
    "    <td style=\"text-align:center;\">54.9 / 57.9</td>\n",
    "    <td style=\"text-align:center;\">47.4</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "<span class=\"badge badge-secondary\">(Le et al., 2010)</span> Hang Le, Lo√Øc Vial, Jibril Frej, Vincent Segonne, Maximin Coavoux, Benjamin Lecouteux, Alexandre Allauzen, Beno√Æt Crabb√©, Laurent Besacier, Didier Schwab: FlauBERT: Unsupervised Language Model Pre-training for French. LREC 2020: 2479-2490"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import des librairies"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%capture\n",
    "\n",
    "# ‚ö†Ô∏è Execute only if running in Colab\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "  IN_COLAB = True\n",
    "else:\n",
    "  IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "  !pip install unidecode\n",
    "  !pip install -q scikit-learn==0.23.2 matplotlib==3.3.2 pandas==1.1.3 nltk==3.5 spacy==2.3.2 \n",
    "  !python3 -m spacy download fr_core_news_md\n",
    "  !pip install lime==0.2.0\n",
    "  !pip install umap-learn==0.4.6 umap-learn[plot] \n",
    "  # if running Colab, restart after libraries installation (Red√©marrer l'environnement d'ex√©cution)\n",
    "  # exit()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os, sys\n",
    "import numpy as np  # python base math library\n",
    "import pandas as pd # data structure\n",
    "\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set matplotlib fonts\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = 'Helvetica'\n",
    "\n",
    "# set the style of the axes and the text color\n",
    "plt.rcParams['axes.edgecolor']='#333F4B'\n",
    "plt.rcParams['axes.linewidth']=0.8\n",
    "plt.rcParams['xtick.color']='#333F4B'\n",
    "plt.rcParams['ytick.color']='#333F4B'\n",
    "plt.rcParams['text.color']='#333F4B'\n",
    "\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "# IPython automatically reload all changed code\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Inline Figures with matplotlib\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import extrenal modules\n",
    "import urllib.request\n",
    "\n",
    "repo_url = 'https://raw.githubusercontent.com/AntoineSimoulin/m2-data-sciences/master/'\n",
    "_ = urllib.request.urlretrieve(repo_url + 'src/plots.py', 'plots.py')\n",
    "_ = urllib.request.urlretrieve(repo_url + 'src/load_flue_datasets.py', 'load_flue_datasets.py')\n",
    "# !git clone https://github.com/AntoineSimoulin/titulus.git\n",
    "# sys.path.append(os.path.abspath('titulus'))\n",
    "!pip install git+https://github.com/AntoineSimoulin/titulus.git\n",
    "\n",
    "from plots import plot_word_counter, plot_zipf\n",
    "from load_flue_datasets import load_cls_dataset\n",
    "# try:\n",
    "from titulus import color, print_\n",
    "# except:\n",
    "#     from titulus.titulus import color, print_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# get data\n",
    "\n",
    "for cat in ['books', 'dvd', 'music']:\n",
    "  dir = './data/{}'.format(cat)\n",
    "  if not os.path.exists(dir):\n",
    "    os.makedirs(dir)\n",
    "    \n",
    "  for split in ['train', 'valid', 'test']:\n",
    "    data_file = './data/{}/{}_0.tsv'.format(cat, split)\n",
    "    if not os.path.isfile(data_file): \n",
    "      urllib.request.urlretrieve(repo_url + 'TP1%20-%20Apprentissage%20supervis%C3%A9%20pour%20le%20NLP/data/{}/{}_0.tsv'.format(cat, split), data_file)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Classification de texte"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"https://monkeylearn.com/static/507a7b5d0557f416857a038f553865d1/5040b/text_process_training.png\" width=\"500\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1 Chargement des donn√©es"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_dir = './data/'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_books, y_books = load_cls_dataset(data_dir, 'books')\n",
    "X_dvd, y_dvd = load_cls_dataset(data_dir, 'dvd')\n",
    "X_music, y_music = load_cls_dataset(data_dir, 'music')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train_df = pd.DataFrame.from_dict(\n",
    "    {'reviews': X_books['train'] + X_dvd['train'] + X_music['train'],\n",
    "     'section': ['books' for _ in range(len(X_books['train']))] \\\n",
    "     + ['dvd' for _ in range(len(X_dvd['train']))] \\\n",
    "     + ['music' for _ in range(len(X_music['train']))]})\n",
    "\n",
    "y_train = y_books['train'] + y_dvd['train'] + y_music['train']\n",
    "\n",
    "X_valid_df = pd.DataFrame.from_dict(\n",
    "    {'reviews': X_books['valid'] + X_dvd['valid'] + X_music['valid'],\n",
    "     'section': ['books' for _ in range(len(X_books['valid']))] \\\n",
    "     + ['dvd' for _ in range(len(X_dvd['valid']))] \\\n",
    "     + ['music' for _ in range(len(X_music['valid']))]})\n",
    "\n",
    "y_valid = y_books['valid'] + y_dvd['valid'] + y_music['valid']\n",
    "\n",
    "class_names = ['N√©gatif', 'Positif']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train_df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 Data Exploration"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Avant de commencer √† d√©rouler un cas d'usage, vous devez toujours **analyser les donn√©es**. V√©rifiez les valeurs manquantes ou ab√©rrantes, la distribution des variables, l'√©quilibre des classes, s√©lectionnez ou √©cartez les variables en fonction de leur pertinence ou selon des crit√®res √©thiques."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p><b>Exercice :</b> Comparer la distribution des labels positifs / n√©gatifs.</p>\n",
    "</div>    "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# %load solutions/plot_labels_distribution.py\n",
    "set(y_books['train']), set(y_books['valid'])\n",
    "np.mean(y_books['train']), np.mean(y_books['valid'])\n",
    "\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "ax.bar(unique, counts, alpha=0.8, color='#970137', linewidth=15)\n",
    "\n",
    "# set labels\n",
    "ax.set_ylabel('Distribution des Labels', fontsize=15,\n",
    "              fontweight='black', color='#333F4B')\n",
    "ax.set_xlabel('')\n",
    "ax.set_title('')\n",
    "\n",
    "# set axis\n",
    "plt.xticks([])\n",
    "\n",
    "# change the style of the axis spines\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['right'].set_color('none')\n",
    "\n",
    "# set the spines position\n",
    "ax.spines['left'].set_position(('axes', 0.015))\n",
    "# plt.yscale('log')\n",
    "\n",
    "# Add labels at the top of the bar\n",
    "for idx, f, w in zip(range(len(counts)), counts, unique):\n",
    "\n",
    "    label = \"{}\".format(class_names[w])\n",
    "    plt.annotate(label,                      # this is the text\n",
    "                 (idx, f),                   # this is the point to label\n",
    "                 textcoords=\"offset points\", # how to position the text\n",
    "                 xytext=(0,20),              # distance from text to points (x,y)\n",
    "                 ha='center',                # horizontal alignment can be left, right or center\n",
    "                 rotation=90,\n",
    "                 fontsize=15,\n",
    "                 weight='bold')\n",
    "\n",
    "    label = \"{:.0f}\".format(f)\n",
    "    plt.annotate(label, (idx, f), textcoords=\"offset points\",\n",
    "                 xytext=(1, -40 - len(label)), ha='center',\n",
    "                 rotation=90, fontsize=15,  weight='bold', color='white')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p><b>Exercice :</b> Comparer la distribution des sections <i>books</i>, <i>dvd</i> et <i>music</i>.</p>\n",
    "</div>    "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# %load solutions/plot_sections_distribution.py\n",
    "# Repr√©senter la distributions des labels\n",
    "\n",
    "unique, counts = np.unique(X_train_df['section'], return_counts=True)\n",
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "\n",
    "ax.bar(unique, counts, alpha=0.8, color='#970137', linewidth=15)\n",
    "\n",
    "# set labels\n",
    "ax.set_ylabel('R√©parition des S√©lections', fontsize=15,\n",
    "              fontweight='black', color='#333F4B')\n",
    "ax.set_xlabel('')\n",
    "ax.set_title('')\n",
    "\n",
    "# set axis\n",
    "plt.xticks([])\n",
    "\n",
    "# change the style of the axis spines\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['right'].set_color('none')\n",
    "\n",
    "# set the spines position\n",
    "ax.spines['left'].set_position(('axes', 0.015))\n",
    "# plt.yscale('log')\n",
    "\n",
    "# Add labels at the top of the bar\n",
    "for idx, f, w in zip(range(len(counts)), counts, unique):\n",
    "\n",
    "    label = \"{}\".format(w)\n",
    "    plt.annotate(label,                      # this is the text\n",
    "                 (idx, f),                   # this is the point to label\n",
    "                 textcoords=\"offset points\", # how to position the text\n",
    "                 xytext=(0,20),              # distance from text to points (x,y)\n",
    "                 ha='center',                # horizontal alignment can be left, right or center\n",
    "                 rotation=90,\n",
    "                 fontsize=15,\n",
    "                 weight='bold')\n",
    "\n",
    "    label = \"{:.0f}\".format(f)\n",
    "    plt.annotate(label, (idx, f), textcoords=\"offset points\",\n",
    "                 xytext=(1, -40 - len(label)), ha='center',\n",
    "                 rotation=90, fontsize=15,  weight='bold', color='white')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p><b>Exercice :</b> Comparer la distribution de la longueur des phrases sur le jeu de donn√©es d'entrainement et de validation.</p>\n",
    "</div>    "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# %load solutions/plot_sentence_length_distribution.py\n",
    "# Repr√©senter la longueur des phrases\n",
    "\n",
    "n_bins = 20\n",
    "\n",
    "x_train = X_train_df['reviews'].apply(lambda x: len(x.split()))\n",
    "x_valid = X_valid_df['reviews'].apply(lambda x: len(x.split()))\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True, figsize=(20, 8))\n",
    "\n",
    "axs[0].set_ylabel('Nombre de phrases', fontsize=15,\n",
    "                  fontweight='black', color='#333F4B')\n",
    "axs[0].set_xlabel('Longueur des phrase pour le jeu d\\'entrainement', fontsize=15,\n",
    "                  fontweight='black', color='#333F4B')\n",
    "axs[1].set_xlabel('Longueur des phrase pour le jeu de validation', fontsize=15,\n",
    "                  fontweight='black', color='#333F4B')\n",
    "\n",
    "axs[0].hist(x_train, bins=n_bins, alpha=0.8, color='#970137', linewidth=15);\n",
    "axs[1].hist(x_valid, bins=n_bins, alpha=0.8, color='#970137', linewidth=15);"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p><b>Exercice :</b> Etudier la distribution des caract√®res dans corpus.</p>\n",
    "</div>    "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# %load solutions/characters_distribution.py\n",
    "# compter les caract√®res dans corpus\n",
    "character_counts = Counter(\" \".join(X_train_df['reviews'].tolist()))\n",
    "\n",
    "print(\"Most common characters in corpus : \")\n",
    "print(character_counts.most_common(10))\n",
    "\n",
    "print(\"\\nNumber of characters in the dataset: {}.\".format(len(character_counts)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p><b>Exercice :</b> V√©rifier s'il y a des donn√©es manquantes (labels, reviews).</p>\n",
    "</div>    "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3 Data Preparation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# !pip install unidecode\n",
    "import unidecode\n",
    "import re # Regular Expression (Regex) in Python\n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS\n",
    "from spacy.tokens import Doc\n",
    "nlp = spacy.load('fr_core_news_md')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p><b>Exercice :</b> Effectuer la tokenization du jeu de donn√©es. Pour cela cr√©er une nouvelle colonne <b>tokens</b> dans la DataFrame. Vous pouvez utiliser la m√©thode de votre choix, Spacy, regex ...</p>\n",
    "</div>    "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# %load solutions/tokenization.py\n",
    "\n",
    "def tokenize(text):\n",
    "    # TODO compl√©ter la fonction de tokenization\n",
    "    return tokens\n",
    "\n",
    "# on peut tester la fonction sur un exemple\n",
    "tokenize(\"Je voulais mettre 0 √©toile mais c'est pas possible... \"\n",
    "         \"Commen√ßons par le positif (c'est rapide): √ßa parle de tout : \"\n",
    "         \"muxle, endurance, souplesse, alimentation, √©chauffement mais ...\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# On applique ensuite la fonction √† l'ensemble de la dataframe\n",
    "X_train_df['tokens'] = X_train_df['reviews'].apply(tokenize)\n",
    "X_valid_df['tokens'] = X_valid_df['reviews'].apply(tokenize)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train_df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Standardisation de texte : suppression des accents et mettre en minuscules\n",
    "\n",
    "def remove_accents(token):\n",
    "    return unidecode.unidecode(token)\n",
    "\n",
    "X_train_df['tokens'] = X_train_df['tokens'].apply(lambda x: [remove_accents(t) for t in x])\n",
    "X_valid_df['tokens'] = X_valid_df['tokens'].apply(lambda x: [remove_accents(t) for t in x])\n",
    "\n",
    "X_train_df['tokens'] = X_train_df['tokens'].apply(lambda x: [t.lower() for t in x])\n",
    "X_valid_df['tokens'] = X_valid_df['tokens'].apply(lambda x: [t.lower() for t in x])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train_df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Lemmatization : on ram√®ne chaque mot √† son \"lem\", pour les verbes, la forme non conjugu√©e \n",
    "\n",
    "# On va utiliser le tokenizer que l'on a d√©finit comme fonction de base dans SpaCy\n",
    "def custom_tokenizer(text):\n",
    "    tokens = tokenize(text)\n",
    "    return Doc(nlp.vocab, tokens)\n",
    "\n",
    "nlp.tokenizer = custom_tokenizer\n",
    "\n",
    "doc = nlp(X_train_df.loc[0, 'reviews'])\n",
    "for token in doc[:10]:\n",
    "    print(token, token.lemma_)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def lemmatize(text):\n",
    "    doc = nlp(str(text))\n",
    "    return [token.lemma_ for token in doc]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(' '.join(lemmatize(X_train_df.loc[0, 'reviews'])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Stemming : on enl√®ve les \"terminaisons\" des mots\n",
    "\n",
    "stemmer = FrenchStemmer()\n",
    "\n",
    "for token in X_train_df.loc[0, 'tokens'][:10]:\n",
    "    print(token, stemmer.stem(token))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def stemmatize(tokens):\n",
    "    return [stemmer.stem(t) for t in tokens]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(' '.join(stemmatize(X_train_df.loc[0, 'tokens'])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p><b>Exercice :</b> Observer l'impact de la stemmatisation sur le jeu de donn√©es (en particulier sur la taille du vocabulaire).</p>\n",
    "</div>    "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train_df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%time\n",
    "X_train_df['tokens_stem'] = X_train_df['tokens'].apply(stemmatize)\n",
    "X_train_df['tokens_lem'] = X_train_df['reviews'].apply(lemmatize)\n",
    "\n",
    "X_valid_df['tokens_stem'] = X_valid_df['tokens'].apply(stemmatize)\n",
    "X_valid_df['tokens_lem'] = X_valid_df['reviews'].apply(lemmatize)\n",
    "\n",
    "\n",
    "tokens = [ll for l in X_train_df.tokens.values for ll in l]\n",
    "tokens_stem = [ll for l in X_train_df.tokens_stem.values for ll in l]\n",
    "tokens_lem = [ll for l in X_train_df.tokens_lem.values for ll in l]\n",
    "\n",
    "\n",
    "vocab_initial = np.unique(tokens)\n",
    "vocab_stem = np.unique(tokens_stem)\n",
    "vocab_lem = np.unique(tokens_lem)\n",
    "\n",
    "label_init  = \"Vocabulaire initial : \" + str(len(vocab_initial))\n",
    "label_stem = \"Vocabulaire apres stemmatisation : \" + str(len(vocab_stem))\n",
    "label_lem = \"Vocabulaire apres lemmatization : \" + str(len(vocab_lem))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "\n",
    "ax.bar([1,2,3], [len(vocab_initial), len(vocab_lem), len(vocab_stem)], color='#970137', alpha=0.8, linewidth=15)\n",
    "\n",
    "# set labels\n",
    "ax.set_ylabel('Taille du vocabulaire', fontsize=15,\n",
    "              fontweight='black', color='#333F4B')\n",
    "ax.set_xlabel('')\n",
    "ax.set_title('Impact des pr√©traitements sur la taille du vocabulaire')\n",
    "\n",
    "# set axis\n",
    "plt.xticks([])\n",
    "\n",
    "#set annotation\n",
    "plt.annotate(label_init, (1, len(vocab_initial)), textcoords=\"offset points\",\n",
    "                 xytext=(1, -40 - len(label)), ha='center',\n",
    "                 fontsize=15,  weight='bold', color='white')\n",
    "plt.annotate(label_lem , (2, len(vocab_lem)), textcoords=\"offset points\",\n",
    "                 xytext=(1, -40 - len(label)), ha='center',\n",
    "                 fontsize=15,  weight='bold', color='white')\n",
    "plt.annotate(label_stem , (3, len(vocab_stem)), textcoords=\"offset points\",\n",
    "                 xytext=(1, -40 - len(label)), ha='center',\n",
    "                 fontsize=15,  weight='bold', color='white')\n",
    "\n",
    "plt.show();"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# %load solutions/stemming_impact.py\n",
    "# Observer l'impact sur la taille du vocabulaire\n",
    "\n",
    "tokenized_corpus_flatten = [ll for l in X_valid_df['tokens'].values for ll in l]\n",
    "tokens_counter = Counter(tokenized_corpus_flatten)\n",
    "\n",
    "print(\"without stemmatization\")\n",
    "print(\"Validation set contains {:,} unique words.\".format(len(tokens_counter)))\n",
    "\n",
    "n_tokens = sum([len(t) for t in X_valid_df['tokens'].values])\n",
    "print(\"Validation set contains {:,d} tokens.\".format(n_tokens))\n",
    "\n",
    "assert len(tokenized_corpus_flatten) == n_tokens\n",
    "\n",
    "X_valid_df['tokens_stem'] = X_valid_df['tokens'].apply(stemmatize)\n",
    "\n",
    "tokenized_corpus_flatten = [ll for l in X_valid_df['tokens_stem'].values for ll in l]\n",
    "tokens_counter = Counter(tokenized_corpus_flatten)\n",
    "\n",
    "print(\"with stemmatization\")\n",
    "n_tokens = sum([len(t) for t in X_valid_df['tokens_stem'].values])\n",
    "print(\"Validation set contains {:,d} tokens.\".format(n_tokens))\n",
    "\n",
    "print(\"Validation set contains {:,} unique words.\".format(len(tokens_counter)))\n",
    "\n",
    "# X_valid_df['tokens'] = X_valid_df['reviews'].apply(lambda x: [lemmatize(t) for t in x])\n",
    "\n",
    "# tokenized_corpus_flatten = [ll for l in X_valid_df['tokens'].values for ll in l]\n",
    "# tokens_counter = Counter(tokenized_corpus_flatten)\n",
    "\n",
    "# n_tokens = sum([len(t) for t in X_valid_df['tokens'].values])\n",
    "# print(\"Validation set contains {:,d} tokens.\".format(n_tokens))\n",
    "\n",
    "# print(\"Validation set contains {} unique words.\".format(len(tokens_counter)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.4 Feature Engineering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer  \n",
    "# Sklearn is a famous french ML library"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "On va chercher √† encoder les donn√©es comme discut√© pendant le premier cours. Le texte va √™tre \"vectoris√©\" afin de pouvoir √™tre trait√© par des algorithmes. "
   ],
   "metadata": {
    "colab_type": "text",
    "id": "x-RwI4kdjnrw"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Bag of Words** : C'est la repr√©sentation la plus simple. On attribue index √† chacun des mots apparaissant dans le corpus d'entrainement. On peut ensuite repr√©senter chaque document par un vecteur X indiquant la pr√©sence ou l'absence de chaque mot 'w' dans le dictionnaire. La taille du vocabulaire est g√©n√©ralement comprise entre 50.000 et 100.000 mots.\n",
    "\n",
    "De plus la majorit√© des valeurs de X sont nulles puisque pour un document donn√©, seul quelques centaines de mots sont utilis√©s. Ainsi, le bag of words est une repr√©sentation <i>sparse</i> de <i>grande dimension</i>."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "w2MX8tqsjnrw"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# On consid√®re ce corpus exemple. \n",
    "# Le corpus est constitu√© d'un ensemble de documents\n",
    "# Chaque document est d√©fini comme une suite de mots \n",
    "# (la tokenization et lese pr√©traitements sont d√©j√† effectu√©s)\n",
    "\n",
    "document_1 = [\"je\", \"n'\", \"aime\", \"pas\", \"ce\", \"livre\"]\n",
    "document_2 = [\"un\", \"livre\", \"tr√®s\", \"complet\"]\n",
    "document_3 = [\"pas\", \"un\", \"livre\", \"exceptionnel\", \"ni\", \"un\", \"livre\", \"tr√®s\", \"complet\"]\n",
    "\n",
    "corpus = np.array([\n",
    "  document_1,\n",
    "  document_2,\n",
    "  document_3])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<hr>\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p><b>üìù Exercice :</b> Etablir le vocabulaire associ√© au corpus.</p>\n",
    "</div>\n",
    "<hr>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# %load solutions/build_voc.py\n",
    "\n",
    "def build_vocabulary(corpus):\n",
    "  # TODO compl√©ter la fonction de construction du vocabulaire\n",
    "  # Cette derni√®re doit associer √† chaque mot un index. \n",
    "  # Les mots sont g√©n√©ralements tri√©s par ordre alphab√©tique \n",
    "  # ou en fonction de leur fr√©quence d'apparition\n",
    "  return vocabulary\n",
    "\n",
    "vocabulary = build_vocabulary(corpus)\n",
    "print(vocabulary)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Prise en compte de l'aspect fr√©quentiel** chaque text est repr√©sent√© par un vecteur indiquant la fr√©quence de chaque token dans le text."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "7CEIcprxjnrx"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<hr>\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p><b>üìù Exercice :</b> Ecrire une fonction qui associe un document √† sa repr√©sentation fr√©quentielle (Bag of Words).</p>\n",
    "</div>\n",
    "<hr>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def tf(document, vocabulary):\n",
    "    # TODO compl√©ter la fonction de repr√©sentation BoW.\n",
    "    return tf\n",
    "\n",
    "tf(document_1, vocabulary)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "seiU6grVjnry"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# On peut utiliser la librairie sklearn pour comparer.\n",
    "\n",
    "def dummy(document):\n",
    "    return document\n",
    "\n",
    "cv = CountVectorizer(tokenizer=dummy, preprocessor=dummy, vocabulary=vocabulary)\n",
    "bow = cv.fit_transform(corpus).toarray()\n",
    "bow"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fEVt0EJ0jnr0",
    "outputId": "749d8303-107c-43b2-bdcf-44269a9a640d"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**TF-IDF (Term Frequency - Inverse Document Frequency)** : On l'a vu en cours, le probl√®me de ce type d'approche c'est que les mots ont une fr√©quence d'apparition sp√©cifique dans le texte. Pour corriger ce ph√©nom√®ne, on s'appuie sur la repr√©sentation Tf-Idf\n",
    "\n",
    "Cette m√©thode cherche √† r√©duire les poids des mots qui apparaissent dans de nombreux documents du corpus et qui portent donc moins d'information que les mots plus rares."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "uc3DOEnnjnr7"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Calcul des pond√©rations Tf-Idf** \n",
    "\n",
    "$$\\text{tf-idf}(t, d) = \\text{tf}(t, d) \\times \\text{idf}(t)$$\n",
    "\n",
    "ou `idf` et la **inverse document frequency** et `tf` et la **fr√©quence du mot** dans le document calcul√©e pr√©c√©dement."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "u2w0Y84rjnr8"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Calcul du terme TF** : TF peut √™tre calcul√©e de plusieurs mani√®res correspond √† la fr√©quence d'occurence du mot dans le document.\n",
    "\n",
    "**Calcul du terme DF** : On d√©finit la *document frequency* d'un mot dans le corpus, comme le nombre de documents o√π ce mot apparait : $\\mathrm{df}(t) = |\\{d \\in D: t \\in d\\}|$\n",
    "\n",
    "**Calcul de la IDF** : IDF mesure l'importance d'un mot vis √† vis de l'ensemble du corpus ($N$ est le nombre de documents dans le corpus). Elle est calcul√©e en utilisant la notion de *document frequency* $\\text{df}(d,t)$, qui d√©signe simplement le nombre de documents $d$ qui contiennent le term $t$. On peut ainsi d√©finir l'idf commme suit :\n",
    "\n",
    "$$\\text{idf}(t) = log{\\frac{n_d}{1+\\text{df}(d,t)}},$$ \n",
    "avec    $n_d$: Nombre total de documents\n",
    "\n",
    "**Remarque 1 :** la constante 1 est ajout√©e au d√©nominateur pour √©viter les cas de division par 0. :\n",
    "\n",
    "**Remarque 2 :** `Sklearn` utilise une d√©finition diff√©rente de l'IDF classique: \n",
    "$$  \\mathrm{idf}(t) = 1 + \\log \\left( \\frac{N}{\\mathrm{df}(t)}\\right) $$\n",
    "\n",
    "Et dans le cas ou `smooth_idf = True` $$\\mathrm{idf}(t) = 1+ \\log \\left( \\frac{1+N}{1+\\mathrm{df}(t)}\\right)   $$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<hr>\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p><b>üìù Exercice :</b> Calculer les pond√©rations idf du corpus exemple. En d√©duire la repr√©sentation Tf-Idf du premier document.</p>\n",
    "</div>\n",
    "<hr>\n"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "C5T3WeKTjnr9"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def idf(corpus, vocabulary):\n",
    "  # TODO compl√©ter la fonction de calcul des pond√©rations idfs.\n",
    "  return idf\n",
    "\n",
    "idfs = idf(corpus, vocabulary)\n",
    "print(idfs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def tf_idf(document, vocabulary, idfs):\n",
    "    tf_ = tf(document, vocabulary)\n",
    "    return np.multiply(tf_, idfs)\n",
    "\n",
    "tf_idf(document_1, vocabulary, idfs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# On peut √©galement utiliser la librairie sklearn pour comparer.\n",
    "\n",
    "tfidf_vec = TfidfVectorizer(tokenizer=dummy, preprocessor=dummy, vocabulary=vocabulary,\n",
    "                            token_pattern=None, smooth_idf=False, norm=None)\n",
    "tfidf_vec.fit(corpus)\n",
    "tfidf_vec.transform([document_1]).toarray()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<hr>\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p><b>üìù Exercice :</b> Modifier la configuration de la classe <b>TfidfVectorizer</b> pour retrouver la repr√©sentation obtenue avec la classe <b>CountVectorizer</b>.</p>\n",
    "</div>\n",
    "<hr>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# %load solutions/count_with_tfidf.py\n",
    "# solution\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "tfidf_vec.fit(corpus)\n",
    "tfidf_vec.transform(corpus).toarray()"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "12k4SwXyjnsB",
    "outputId": "81c6024c-a64b-4c43-8fa7-46d1b6854f49"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<b>Les param√®tres du Tf-Idf : S√©lection de features</b>\n",
    "\n",
    "L'ensemble des documents du corpus peuvent contenir un tr√®s grand nombre de tokens distincts ainsi que de ngrams et de caract√®res. Ainsi la repr√©sentation obtenur peut √™tre de tr√®s grande dimension. Pourtant l'ensemble des tokens (features) ne contribuent pas tous √† augmenter la pr√©cision des algorithmes de classifications. \n",
    "\n",
    "Nous pouvons donc ne pas tenir compte de certains tokens. Pour cela il est possible de jouer sur de nombreux param√®tres du Tf-Idf. On consid√®re g√©n√©ralement que 20,000 features sont amplement suffisants. De plus un tr√®s grand nombre de features peut conduire √† un ph√©nom√®ne d'overfitting et √† une d√©gradation des performances de l'algorithme."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "ztkoNvlsjnsC"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Param√®tre `analyzer`** Prend en argument ‚Äòword‚Äô pour effectuer la transformation sur les mots, ou ‚Äòchar‚Äô pour effectuer la transformation sur les lettres."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "dnJdapeWjnsC"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vec = TfidfVectorizer(analyzer=\"word\")\n",
    "X = vec.fit_transform(X_train_df['reviews'])\n",
    "print(\"Taille du vocabulaire: {:,}\".format(len(vec.vocabulary_)))"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M960F08HjnsC",
    "outputId": "5fc309bb-507a-4f6e-e31c-1559c67c7a80"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vec = TfidfVectorizer(analyzer=\"char\")\n",
    "X = vec.fit_transform(X_train_df['reviews'])\n",
    "print(\"Taille du vocabulaire: {:,}\".format(len(vec.vocabulary_)))\n",
    "print(vec.vocabulary_)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N9eAYct9jnsD",
    "outputId": "90b84df5-5f1d-4ad1-953b-f747950cb3cb"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Param√®tres `max_df` et `min_df`** Prend en argument un float compris dans [0.0, 1.0] ou un int. max_df permet de supprimer les termes de fr√©quence √©lev√©e et min_df permet de supprimer les termes de fr√©quence faible."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "qH4P_0L7jnsE"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vec = TfidfVectorizer(max_df=0.8) # min_df=5\n",
    "X = vec.fit_transform(X_train_df['reviews'])\n",
    "print(\"Taille du vocabulaire: {:,}\".format(len(vec.vocabulary_)))"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VaeLpHCkjnsE",
    "outputId": "04ec50f8-6b45-4238-bc7a-8894e129c7db"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Param√®tre `max_features`** Permet de limiter le nombre de mots utilis√©s."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "IP-cfM6CjnsI"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vec = TfidfVectorizer(max_features=10000)\n",
    "X = vec.fit_transform(X_train_df['reviews'])\n",
    "print(\"Taille du vocabulaire: {:,}\".format(len(vec.vocabulary_)))"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8YqrWI8ljnsJ",
    "outputId": "edc915f1-0a51-488e-b1e8-bc0c284d0f27"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Param√®tre `stop_words`** Permet de supprimer certains mots sp√©cifiques du vocabulaire."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "uXgiqipVjnsM"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(STOP_WORDS)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AHA15TI1jnsM",
    "outputId": "80984ff1-f09c-4462-c7bc-7bd5674c901c"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vec = TfidfVectorizer(stop_words=STOP_WORDS)\n",
    "X = vec.fit_transform(X_train_df['reviews'])\n",
    "print(\"Taille du vocabulaire: {:,}\".format(len(vec.vocabulary_)))"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GlQv-eJtjnsN",
    "outputId": "0f1eed25-4054-44c6-a7f4-c0940e674767"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Param√®tre `ngram_range`** Permet d'int√©grer dans l'espace des features des suites de mots ou de caract√®res."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "6FVwqAodjnsP"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vec = TfidfVectorizer(ngram_range = (1,2))\n",
    "X = vec.fit_transform(X_train_df['reviews'])\n",
    "print(\"Taille du vocabulaire: {:,}\".format(len(vec.vocabulary_)))"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AU2WFpWgjnsP",
    "outputId": "e0b9cb58-1531-4ba8-bede-2a820e1521a6"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p><b>Exercice :</b> Supprimer les mots \"je\", \"le\" du dictionnaire de vocabulaire mais pas \"livres\" ou \"oeuvre\".</p>\n",
    "</div>    "
   ],
   "metadata": {
    "colab_type": "text",
    "id": "BSUdAZJ8jnsR"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# %load solutions/filter_tfidf_voc.py\n",
    "vec = CountVectorizer(max_features=10000)\n",
    "bag_of_word = vec.fit_transform(X_train_df['reviews'])\n",
    "\n",
    "sum_words = bag_of_word.sum(axis=0)\n",
    "word_freq = {word: sum_words[0, idx] for word, idx in vec.vocabulary_.items()}\n",
    "word_freq_sorted = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "word_freq_sorted = sorted(word_freq_sorted, key=lambda x: x[1], reverse=True)\n",
    "word_freq_sorted = [x[0] for x in word_freq_sorted]\n",
    "\n",
    "for word in ['je', 'le', 'livres', 'oeuvre']:\n",
    "    print(\"frequence d'occurence de \\'%s\\' : %i\" % (word, word_freq[word]))\n",
    "    print(\"top fr√©quence de \\'%s\\' : %i\" % (word, word_freq_sorted.index(word)))\n",
    "\n",
    "vec = TfidfVectorizer()\n",
    "vec.fit(X_train_df['reviews'])\n",
    "word_idf = {word: vec.idf_[idx] for word, idx in vec.vocabulary_.items()}\n",
    "\n",
    "for word in ['je', 'le', 'livres', 'oeuvre']:\n",
    "    print(\"idf de \\'%s\\' : %f\" % (word, word_idf[word]))\n",
    "\n",
    "vec = TfidfVectorizer(max_df=0.2)\n",
    "vec.fit(X_train_df['reviews'])\n",
    "word_idf = {word: vec.idf_[idx] for word, idx in vec.vocabulary_.items()}\n",
    "\n",
    "for word in ['je', 'le', 'livres', 'oeuvre']:\n",
    "    print(\"%s in voc :\" % word, word in word_idf)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "omFx7_tojnsR",
    "outputId": "0836dcc2-f75e-4003-c446-2d74d3d4b9e3"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000,\n",
    "                             max_df=0.8,\n",
    "                             min_df=5,\n",
    "                              # ngram_range=(1, 3),\n",
    "                             tokenizer=lambda x: x,\n",
    "                             lowercase=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train_tfidf = vectorizer.fit_transform(X_train_df['tokens'])\n",
    "X_valid_tfidf = vectorizer.transform(X_valid_df['tokens'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(vectorizer.get_feature_names())"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_tfidf_arr = X_train_tfidf.toarray()\n",
    "voc_tfidf = vectorizer.get_feature_names()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vectorizer = CountVectorizer(max_features=5000,\n",
    "                             ngram_range=(1, 3),\n",
    "                             tokenizer=lambda x: x,\n",
    "                             lowercase=False)\n",
    "\n",
    "X_train_counter = vectorizer.fit_transform(X_train_df['tokens'])\n",
    "X_valid_counter = vectorizer.transform(X_valid_df['tokens'])\n",
    "\n",
    "X_counter_arr = X_train_counter.toarray()\n",
    "voc_counter = vectorizer.get_feature_names()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Visualisation des poids en fonction de la fr√©quence\n",
    "\n",
    "idx = np.random.randint(len(X_counter_arr))\n",
    "\n",
    "tokens = X_train_df.loc[idx, 'tokens']\n",
    "token_idx = [voc_counter.index(t) if t in voc_counter else -1 for t in tokens]\n",
    "\n",
    "counter_weights = [X_counter_arr[idx, t] if t >=0 else 0 for t in token_idx]\n",
    "\n",
    "print_(' '.join(color(tokens, counter_weights, finish_hex=\"#970137\", n=10)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Visualisation des poids TF-IDF\n",
    "\n",
    "tokens = X_train_df.loc[idx, 'tokens']\n",
    "token_idx = [voc_tfidf.index(t) if t in voc_tfidf else -1 for t in tokens]\n",
    "\n",
    "tfidf_weights = [X_tfidf_arr[idx, t] if t >=0 else 0 for t in token_idx]\n",
    "\n",
    "print_(' '.join(color(tokens, tfidf_weights, finish_hex=\"#970137\", n=10)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.5 Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"https://monkeylearn.com/static/afa7e0536886ee7152dfa4c628fe59f0/5040b/text_process_prediction.png\" width=\"500\">\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Instanciate classifier\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    random_state=0, \n",
    "    solver='lbfgs',\n",
    "    multi_class='ovr',\n",
    "    penalty='l2',\n",
    "    C=1.0,\n",
    "    n_jobs=2\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Train classifier\n",
    "\n",
    "clf.fit(X_train_tfidf, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.6 Choix de la m√©trique de performance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pour √©valuer les performances d'un classificateur 3 indicateurs son g√©n√©ralement √©tudi√©s :\n",
    "\n",
    "* Le **score de pr√©cision** : le taux de pr√©dictions corrects parmis les individus pr√©dits comme positifs.\n",
    "* Le **score de rappel** : le taux d'individus positifs correctement pr√©dits.\n",
    "* Le **score F1** : moyenne harmonique des scors de pr√©cision et de rappel.\n",
    "* La **matrice de confusion** permet de repr√©senter le mani√®re simple le nombre de vrais positifs, faux positifs, vrais n√©gatifs et faux n√©gatifs."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Metric de performance train et test\n",
    "\n",
    "# Compare train and validation score to check overfitting\n",
    "# Use the validation set to do the hyper-parameter tuning\n",
    "f1_train = f1_score(y_train, clf.predict(X_train_tfidf), average='macro')\n",
    "f1_validation = f1_score(y_valid, clf.predict(X_valid_tfidf), average='macro')\n",
    "\n",
    "print(f\"Score on the train set : {'%.2f' %f1_train}\")\n",
    "print(f\"Score on the validation set : {'%.2f' %f1_validation}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Matrice de confusion\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.set_printoptions(precision=2)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confusion_matrix(y_valid, clf.predict(X_valid_tfidf)), \n",
    "                      classes=class_names, \n",
    "                      title='Confusion matrix, without normalization')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_logreg_pred = clf.predict(X_valid_tfidf)\n",
    "\n",
    "print(\"Matrice de confusion de la r√©gression logistique : \")\n",
    "print(confusion_matrix(y_valid, y_logreg_pred))\n",
    "print(\"Score de pr√©cision de la r√©gression logisitique : \"+str(round(precision_score(y_valid, y_logreg_pred)*100,2)))\n",
    "print(\"Score de rappel de la r√©gression logisitique : \"+str(round(recall_score(y_valid, y_logreg_pred)*100,2)))\n",
    "print(\"Score F1 de la r√©gression logisitique : \"+str(round(f1_score(y_valid, y_logreg_pred)*100,2)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<b>Comparaison des mod√®les : Naive Bayes, SVM, r√©gression logistique, algorithme de boosting</b>\n",
    "\n",
    "\n",
    "Maintenant que les √©tapes classiques de r√©solution d'un probl√®me de classification ont √©t√© abord√©s nous sommes arm√©s pour comparer diff√©rents mod√®les de transformation des variables et de classification √† l'aune de leurs performances."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<hr>\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p><b>üìù Exercice (BONUS) :</b> Comparer le mod√®le de regression logistique avec un mod√®le de for√™t al√©atoire.</p>\n",
    "</div>\n",
    "<hr>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<hr>\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p><b>üìù Exercice :</b> Evaluer l'impact de la taille du vocabulaire du tf-idf sur la pr√©cision du mod√®le.</p>\n",
    "</div>\n",
    "<hr>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<hr>\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p><b>üìù Exercice (BONUS) :</b> Optimiser les param√®tres du mod√®le pour obtenir un F1-score sup√©rieure √† 0.85 sur le jeu de dev. On pourra comparer faire varier plusieurs caract√©ristiques comme l'impact du pre-processing, le Stemming, Lemmatization ou encore Choix du vectorizer, count vs Tf-Idf ou le mod√®le.</p>\n",
    "</div>\n",
    "<hr>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.7 Choix des hyper-param√®tres"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dans la section pr√©c√©dente, on a cherch√© les hyper-param√®tres √† la main. Il est √©galement possible de mettre en place une proc√©dure de recherche automatique d'hyper-paramt√®tres."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import svm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Creation du pipeline Sklearn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class TextCleaner(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, do_lower=False, remove_accents=True):\n",
    "        self.do_lower = do_lower\n",
    "        self.remove_accents = remove_accents\n",
    "    \n",
    "    def _normalize(self, text):\n",
    "        return unidecode.unidecode(text)\n",
    "    \n",
    "    def fit(self, X, y=None): \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.copy()\n",
    "            if self.remove_accents:\n",
    "                X['reviews'] = X['reviews'].apply(self._normalize)        \n",
    "        else:\n",
    "            if not isinstance(X, list):\n",
    "                X = [X] \n",
    "            if self.remove_accents:\n",
    "                X = [self._normalize(x) for x in X]\n",
    "\n",
    "        return X"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Tokenizer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, tokenizer_pattern=r\"(?:[a-zA-Z√Ä-√ñ√ò-√∂0-9])+'?\",\n",
    "                 do_lemmatization=False,\n",
    "                 do_stemmatization=False):\n",
    "\n",
    "        # self.token_pattern = re.compile(tokenizer_pattern)\n",
    "        self.do_stemmatization = do_stemmatization\n",
    "        self.do_lemmatization = do_lemmatization\n",
    "        if self.do_stemmatization:\n",
    "            self.stemmer = FrenchStemmer()\n",
    "\n",
    "        if self.do_lemmatization:\n",
    "            self.nlp = spacy.load('fr_core_news_md')\n",
    "            self.nlp.tokenizer = self.custom_tokenizer\n",
    "\n",
    "    def _custom_tokenizer(self, text):\n",
    "        tokens = self._tokenize(text)\n",
    "        return Doc(nlp.vocab, tokens)\n",
    "\n",
    "    def _lemmatize(self, text):\n",
    "        doc = self.nlp(X_train_df.loc[0, 'reviews'])\n",
    "        return [token.lemma_ for token in doc]\n",
    "\n",
    "    def _stemmatize(self, tokens):\n",
    "        return [self.stemmer.stem(t) for t in tokens]\n",
    "\n",
    "    def _tokenize(self, text):\n",
    "        tokens = re.findall(r\"(?:[a-zA-Z√Ä-√ñ√ò-√∂0-9])+'?\", text)  # self.token_pattern\n",
    "        tokens = [t for t in tokens]\n",
    "        return tokens\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.copy()\n",
    "        else:\n",
    "            if not isinstance(X, list):\n",
    "                X = [X]\n",
    "\n",
    "        if self.do_lemmatization:\n",
    "            if isinstance(X, pd.DataFrame):\n",
    "                X[\"tokens\"] = X[\"reviews\"].apply(self._lemmatize)\n",
    "            else:\n",
    "                tokens = [self._lemmatize(x) for x in X]\n",
    "        else:\n",
    "            if isinstance(X, pd.DataFrame):\n",
    "                X[\"tokens\"] = X[\"reviews\"].apply(self._tokenize)\n",
    "            else:\n",
    "                tokens = [self._tokenize(x) for x in X]\n",
    "        if self.do_stemmatization:\n",
    "            if isinstance(X, pd.DataFrame):\n",
    "                X[\"tokens\"] = X[\"tokens\"].apply(self._stemmatize)\n",
    "            else:\n",
    "                tokens = [self._stemmatize(x) for x in X]\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            return X[\"tokens\"]\n",
    "        else:\n",
    "            return tokens"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Instanciate classes and create Pipeline\n",
    "\n",
    "cleaner = TextCleaner()\n",
    "tokenizer = Tokenizer(do_stemmatization=True)\n",
    "feature_engineering = TfidfVectorizer(max_features=2000,\n",
    "                             max_df=0.8,\n",
    "                             min_df=5,\n",
    "                             # ngram_range=(1, 3),\n",
    "                             tokenizer=lambda x: x,\n",
    "                             lowercase=False)\n",
    "clf = LogisticRegression(\n",
    "    random_state=0, \n",
    "    solver='lbfgs',\n",
    "    multi_class='ovr',\n",
    "    penalty='l2',\n",
    "    C=10,\n",
    "    n_jobs=2\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([('cleaning', cleaner), \n",
    "                     ('tokenization', tokenizer), \n",
    "                     ('vect', feature_engineering),\n",
    "                     ('clf', clf)])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Fit\n",
    "pipeline.fit(X_train_df, y_train)\n",
    "pipeline.score(X_valid_df, y_valid)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Mise en place de la Proc√©dure de Cross Validation\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "param_grid = {\"vect__max_df\" : [0.95,1.0],\n",
    "              \"vect__min_df\" : [1,5],\n",
    "              \"vect__max_features\" : [1000, 2000],\n",
    "              \"vect__ngram_range\" : [(1,1)],\n",
    "              \"clf__penalty\" : ['l2'],\n",
    "              \"clf__C\" : [0.1, 1.0, 10]\n",
    "              }\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, scoring='accuracy', cv=kfold, verbose=2)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(param_grid)\n",
    "t0 = time()\n",
    "grid_search.fit(X_train_df, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.8 Analyse des r√©sultats"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lime <span class=\"badge badge-secondary\">(T√∫lio Ribeiro et al., 2016)</span> est une m√©thode d'analyse des mod√®les qui cherche √† expliciter sur quelles caract√©ristiques de l'√©chantillon en entr√©e, l'algorithme s'est appuy√© pour formuler sa pr√©diction.\n",
    "\n",
    "Pour cela LIME propose de g√©n√©rer plusieurs √©chantillons proches de l'exemple d'entr√©e et d'apprendre un mod√®le lin√©aire qui cherche √† approcher les pr√©dictions du mod√®les que l'on cherche √† √©tudier sur ce jeu de donn√©es. Par exemple pour la phrase :\n",
    "\n",
    "> Un livre √©mouvant mais aussi tr√®s dr√¥le, magnifiquement √©crit, √† mettre entre toutes les mains sans h√©sitation. Si vous avez un enfant qui aime lire il pourrait l'apr√©cier √† partir de 8 ans, je pense. Et si vous avez gard√© l'envie de vous √©merveiller il vous plairat jusqu'√† 99 ans.\n",
    "\n",
    "\n",
    "On va g√©n√©rer 5000 phrases en perturbant l'exemple original, comme par exemple :\n",
    "\n",
    "> Un livre    tr√®s ,  ,        .           '     , je .      '      plairat ' 99 .\n",
    "\n",
    "> Un livre √©mouvant  aussi tr√®s ,  , √† mettre entre toutes les mains sans h√©sitation.  vous avez un enfant qui aime  il pourrait l'apr√©cier √†  de 8 ans,  . Et si vous avez gard√© l'envie de vous  il vous  jusqu'√† 99 ans.\n",
    "\n",
    "On identifie ensuite les points du jeu de donn√©es pour lesquels on n'arrive pas √† reproduire les pr√©dictions du mod√®les. Ces derniers sont identifi√©s comme des points \"saillants\".\n",
    "\n",
    "Quelques ressources :\n",
    "* Un bon post de [blog](https://www.oreilly.com/content/introduction-to-local-interpretable-model-agnostic-explanations-lime/) pour expliquer LIME.\n",
    "* Le [github](https://github.com/marcotcr/lime) du projet\n",
    "\n",
    "<span class=\"badge badge-secondary\">(T√∫lio Ribeiro et al., 2016)</span>Marco T√∫lio Ribeiro, Sameer Singh, Carlos Guestrin: \"Why Should I Trust You?\": Explaining the Predictions of Any Classifier. KDD 2016: 1135-1144"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from lime.lime_text import LimeTextExplainer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Utilisation module intelligibilit√©\n",
    "\n",
    "# Instanciate classes and create Pipeline\n",
    "cleaner = TextCleaner()\n",
    "tokenizer = Tokenizer()\n",
    "feature_engineering = TfidfVectorizer(max_features=5000,\n",
    "                             max_df=0.8,\n",
    "                             min_df=5,\n",
    "                              # ngram_range=(1, 3),\n",
    "                             tokenizer=lambda x: x,\n",
    "                             lowercase=False)\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "pipeline = Pipeline([('cleaning', cleaner), \n",
    "                     ('tokenization', tokenizer), \n",
    "                     ('vect', feature_engineering),\n",
    "                     ('clf', clf)])\n",
    "\n",
    "pipeline.fit(X_train_df, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(pipeline.predict_proba(X_valid_df.loc[83, 'reviews']))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class_names = ['negatif', 'positif']\n",
    "\n",
    "explainer = LimeTextExplainer(class_names=class_names)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# cf expl 139"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "idx = 139\n",
    "# np.random.randint(X_valid_df.shape[0])\n",
    "print(idx, X_valid_df.loc[idx, 'reviews'])\n",
    "exp = explainer.explain_instance(X_valid_df.loc[idx, 'reviews'], pipeline.predict_proba, num_features=6)\n",
    "print('Document id: %d' % idx)\n",
    "print('Probability(positif) =', pipeline.predict_proba([X_valid_df.loc[idx, 'reviews']])[0,1])\n",
    "print('True class: %s' % class_names[y_valid[idx]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "exp.as_list()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "exp.show_in_notebook(text=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.9 Visualisation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# !pip install umap-learn[plot]\n",
    "import umap\n",
    "import umap.plot"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "UMAP est un algorithme de r√©duction des dimensions. De mani√®re intutive, l'algorithme projete les repr√©sentations dans un espace de plus faible dimension en s'efforcant de respecter les distances entre les points entre l'espace de d√©part et d'arriv√©e. L'objectif est assez similaire √† l'algorithme t-SNE. Il permet de visualiser facilement les donn√©es"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%time\n",
    "# Projection des repr√©sentations avec UMAP\n",
    "# https://umap-learn.readthedocs.io/en/latest/document_embedding.html\n",
    "\n",
    "embedding = umap.UMAP(n_components=2, metric='hellinger').fit(X_train_tfidf)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "embedding.embedding_.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "f = umap.plot.points(embedding, labels=np.array(y_train))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}